[{"uri":"https://vdhxi.github.io/vi/5-workshop/5.3-compute/5.3.1-ec2/","title":"Amazon EC2","tags":[],"description":"","content":"Khởi tạo EC2 Instance Các bước thực hiện 1. Tạo Security Group Tạo SG cho phép HTTP (80), HTTPS (443), SSH (22) và Custom TCP (8080 - port của Spring Boot). 2. Launch Instance Truy cập EC2 Dashboard -\u0026gt; Launch Instances.\nĐặt tên: Auction-Backend.\nChọn OS: Amazon Linux 2023 hoặc Ubuntu. Chọn Instance Type: t3.medium (như đề xuất).\nChọn Key Pair (tạo mới nếu chưa có).\nNetwork settings: Chọn VPC, Public Subnet, và Security Group đã tạo. Configure storage (mặc định 8GB hoặc tăng lên nếu cần).\nAdvanced details:\nIAM instance profile: Chọn Auction-EC2-Role. Nhấn Launch instance.\n3. Gán Elastic IP (Tùy chọn) Nếu bạn muốn IP Public cố định.\nVào Elastic IPs -\u0026gt; Allocate Elastic IP address. Chọn IP vừa tạo -\u0026gt; Associate Elastic IP address. Chọn Instance vừa tạo. "},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.2-database-storage/5.2.1-rds/","title":"Amazon RDS","tags":[],"description":"","content":"Khởi tạo Amazon RDS (MySQL) Chúng ta sẽ sử dụng Amazon RDS MySQL để lưu trữ dữ liệu chính của hệ thống.\nCác bước thực hiện 1. Tạo Security Group cho RDS Trước tiên, cần tạo Security Group cho phép kết nối cổng 3306 từ EC2. 2. Tạo Subnet Group Vào RDS Dashboard -\u0026gt; Subnet groups -\u0026gt; Create DB subnet group. Chọn VPC và các Private Subnet đã tạo. 3. Tạo Database Chọn Databases -\u0026gt; Create database.\nChọn Standard create -\u0026gt; MySQL.\nChọn phiên bản (Engine Version). Chọn Free tier (nếu dùng tài khoản mới) hoặc Dev/Test. Đặt tên DB instance identifier, Master username và password. Chọn Instance class (ví dụ db.t3.micro).\nCấu hình Storage. Cấu hình Connectivity: Chọn VPC, Subnet Group, và Security Group đã tạo. Cấu hình xác thực (Password authentication). Nhấn Create database. "},{"uri":"https://vdhxi.github.io/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Võ Đức Hoàng\nSố điện thoại: 0366934122\nEmail: Hoangvdse182010@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://vdhxi.github.io/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Lợi ích về hiệu năng của các phiên bản Amazon EC2 R8a tối ưu hóa bộ nhớ thế hệ mới Gần đây, chúng tôi công bố việc cung cấp rộng rãi các phiên bản Amazon EC2 R8a — bổ sung mới nhất vào dòng các phiên bản tối ưu hóa bộ nhớ sử dụng CPU AMD. Những phiên bản này được trang bị bộ xử lý AMD EPYC thế hệ thứ 5 (tên mã “Turin”) với tần số tối đa lên tới 4,5 GHz. Trong bài viết này, tôi sẽ thử nghiệm các phiên bản đó và tiến hành benchmark MySQL — nhưng trước hết, hãy cùng điểm qua những đặc điểm quan trọng bạn nên biết về các phiên bản này.\nĐặc điểm nổi bật của phiên bản R8a Mỗi vCPU trên một instance R8a tương ứng với một lõi CPU vật lý (điều mà AWS bắt đầu áp dụng từ các thế hệ AMD thế hệ thứ 7). Điều này nghĩa là không có công nghệ đa luồng đồng thời (SMT). Mỗi vCPU được gán lõi vật lý riêng biệt — giúp mang lại hiệu năng ổn định và nhất quán hơn, bởi tránh được việc chia sẻ tài nguyên hay xung đột giữa các luồng; điều này đặc biệt quan trọng cho các workload nhạy cảm với hiệu năng hoặc độ trễ.\nKhi đánh giá và chuyển sang sử dụng R8a, bạn nên xác định lại ngưỡng sử dụng CPU — vì bạn có thể tận dụng nhiều hơn CPU của mỗi instance mà không làm ảnh hưởng đến SLA (Service Level Agreement) của workload.\nR8a hỗ trợ cấu hình rất rộng — lên đến 192 vCPU với 1.536 GiB RAM. Dưới đây là bảng thông số chi tiết các kích cỡ phổ biến:\nInstance size vCPU Memory (GiB) Instance storage Network bandwidth (Gbps) EBS bandwidth (Gbps) r8a.medium 1 8 EBS Only Up to 12.5 Up to 10 r8a.large 2 16 EBS Only Up to 12.5 Up to 10 r8a.xlarge 4 32 EBS Only Up to 12.5 Up to 10 r8a.2xlarge 8 64 EBS Only Up to 15 Up to 10 r8a.4xlarge 16 128 EBS Only Up to 15 Up to 10 r8a.8xlarge 32 256 EBS Only 15 10 r8a.12xlarge 48 384 EBS Only 22.5 15 r8a.16xlarge 64 512 EBS Only 30 20 r8a.24xlarge 96 768 EBS Only 40 30 r8a.48xlarge 192 1536 EBS Only 75 60 r8a.metal-24xl 96 768 EBS Only 40 30 r8a.metal-48xl 192 1536 EBS Only 75 60 Thử nghiệm hiệu năng MySQL với HammerDB Các phiên bản R8a là lựa chọn tuyệt vời cho cơ sở dữ liệu MySQL, vì vậy tôi cho rằng đây là bối cảnh phù hợp để minh họa những khả năng của các phiên bản này. Để kiểm thử MySQL, tôi sử dụng một loạt script do các đồng nghiệp của tôi phát triển nhằm theo dõi hiệu năng MySQL trên nhiều phiên bản phần mềm và các loại phiên bản EC2 khác nhau. Những script này được lưu trữ trong repository repro-collection, một framework mã nguồn mở, có khả năng mở rộng, được thiết kế cho mục đích kiểm thử hiệu năng dựa trên các workload thực tế thay vì các micro-benchmark. Framework này được xây dựng để cung cấp một chuẩn tham chiếu đo lường hiệu năng có thể sử dụng trên nhiều tổ chức, hiện tập trung chủ yếu vào MySQL và đang được sử dụng tích cực trong các cuộc trao đổi với các nhà phát triển và maintainer của Linux Kernel. Ngoài ra, nó còn hỗ trợ theo dõi bất kỳ tác động hiệu năng nào phát sinh từ các thay đổi mã nguồn của MySQL. Các script trong repository này đảm nhận việc thiết lập một cơ sở dữ liệu MySQL để tiến hành kiểm thử, cùng với một load generator chạy benchmark HammerDB.\nĐối với bài benchmark này, tôi sử dụng một instance r6a.24xlarge làm load generator, và các instance r6a.xlarge, r7a.xlarge, và r8a.xlarge làm máy chủ cơ sở dữ liệu MySQL, tất cả đều được triển khai trong cùng một AWS Availability Zone (AZ). Tôi chọn cấu hình trong một AZ duy nhất để giảm thiểu độ biến thiên độ trễ có thể phát sinh khi lưu lượng phải đi qua nhiều AZ. Đây không phải là cấu hình mô phỏng môi trường production, và tôi rất khuyến nghị sử dụng nhiều AZ đối với các workload chạy trong môi trường production. Mỗi instance MySQL được kiểm thử độc lập bằng cùng một load generator HammerDB. Mỗi bài kiểm thử được chạy ba lần và kết quả được tính trung bình trên ba lần chạy đó. Sơ đồ kiến trúc được minh họa trong hình sau:\nKết quả tổng thể HammerDB Các phiên bản R8a cho thấy hiệu năng vượt trội trong benchmark HammerDB đối với cơ sở dữ liệu MySQL. Ở hạng mục điểm tổng thể của HammerDB, các phiên bản R8a đạt điểm cao hơn 55% so với R7a và cao hơn 74% so với R6a.\nKiểm thử số giao dịch mỗi phút của HammerDB Các phiên bản R8a cũng thể hiện mức cải thiện đáng kể ở hạng mục này. So với các phiên bản R7a thế hệ trước, R8a cho hiệu năng cao hơn 32%. Khi so với các phiên bản R6a, R8a đạt mức cải thiện lên tới 63%.\nKết quả độ trễ P99 của HammerDB Các phiên bản R8a cho thấy mức cải thiện rõ rệt về độ trễ P99, phản ánh hiệu quả từ bộ xử lý AMD EPYC thế hệ thứ 5 cùng với băng thông bộ nhớ cao hơn. R8a đạt mức giảm 14% độ trễ so với R7a và giảm 25% độ trễ so với R6a.\nKết luận Phiên bản R8a, được xây dựng trên nền tảng AWS Nitro System với các Nitro Cards thế hệ thứ sáu, là lựa chọn lý tưởng cho các workload cần hiệu năng cao, sử dụng nhiều bộ nhớ — ví dụ như cơ sở dữ liệu SQL/NoSQL, cache in-memory quy mô web phân tán, database in-memory, phân tích dữ liệu lớn thời gian thực (real-time big data analytics), và các ứng dụng EDA (Electronic Design Automation). Với 12 kích cỡ khác nhau (bao gồm 2 cỡ bare-metal), R8a phù hợp từ các ứng dụng nhỏ đến các hệ thống quy mô lớn. R8a đã được chứng nhận SAP và cung cấp 38% SAPS nhiều hơn so với R7a. Nếu bạn hiện đang dùng các instance R6a (thế hệ 6), bạn nên di chuyển lên R8a để tận dụng lợi ích rõ rệt về giá-hiệu năng. Việc duy trì hạ tầng hiện đại cũng giúp giảm chi phí vận hành và mang lại nhiều tính năng hơn cho khách hàng.\n"},{"uri":"https://vdhxi.github.io/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Tối ưu hóa các workload nhạy cảm với độ trễ bằng thống kê NVMe chi tiết của Amazon EC2 Các instance Amazon Elastic Cloud Compute (Amazon EC2) với bộ lưu trữ NVMe gắn cục bộ có thể cung cấp hiệu năng cần thiết cho các workload đòi hỏi độ trễ cực thấp và thông lượng I/O cao. Các workload hiệu năng cao, từ các ứng dụng giao dịch tần suất cao và cơ sở dữ liệu in-memory đến các công cụ phân tích thời gian thực và suy luận AI/ML, đều cần khả năng theo dõi hiệu năng toàn diện. Các công cụ hệ điều hành như iostat và sar cung cấp những thông tin chi tiết có giá trị ở cấp độ hệ thống, và Amazon CloudWatch cung cấp các phép đo quan trọng về disk IOPs và thông lượng, nhưng các workload hiệu năng cao có thể hưởng lợi từ khả năng hiển thị chi tiết hơn nữa về hiệu năng của instance store.\nĐối với các ứng dụng nhạy cảm với độ trễ mà mỗi mili-giây đều quan trọng, các công cụ giám sát hiệu năng nâng cao cung cấp khả năng hiển thị sâu vào các hệ thống lưu trữ, giúp các đội ngũ của bạn có thể theo dõi và phân tích hành vi ở độ chi tiết 1 giây. Thông tin chi tiết này có thể giúp tổ chức của bạn phát hiện nhanh chóng các điểm nghẽn, tinh chỉnh hiệu năng ứng dụng và cung cấp dịch vụ tin cậy.\nTrong bài viết này, chúng tôi thảo luận về cách bạn có thể sử dụng thống kê hiệu năng chi tiết của Amazon EC2 cho các volume NVMe instance store, một tập hợp các chỉ số mới cung cấp độ chi tiết theo từng giây, để mang lại khả năng hiển thị thời gian thực vào hiệu năng lưu trữ gắn cục bộ của bạn. Các thống kê này tương tự như thống kê hiệu năng chi tiết của Amazon EBS, mang lại trải nghiệm giám sát nhất quán trên cả hai loại lưu trữ. Bạn có thể truy cập các thống kê này trực tiếp từ các thiết bị NVMe được gắn vào instance Amazon EC2 bằng cách sử dụng nvme-cli hoặc sử dụng CloudWatch agent để giám sát hiệu năng I/O ở cấp độ lưu trữ. Chúng tôi cũng cung cấp các ví dụ về cách sử dụng các thống kê này để xác định các điểm nghẽn hiệu năng.\nTổng quan tính năng Các instance dựa trên Amazon EC2 Nitro với bộ lưu trữ instance NVMe gắn cục bộ hiện cung cấp 11 chỉ số toàn diện ở độ chi tiết theo từng giây. Các chỉ số này, tương tự như các chỉ số volume EBS, bao gồm các phép đo độ dài hàng đợi (queue length), IOPS, dữ liệu thông lượng, và biểu đồ phân phối (histogram) độ trễ IO cho bộ lưu trữ instance NVMe gắn cục bộ. Ngoài ra, chúng cũng bao gồm các biểu đồ phân phối độ trễ cụ thể theo kích thước IO để cung cấp thông tin chi tiết hơn nữa về các mẫu hiệu năng của bộ lưu trữ instance NVMe cục bộ. Các chỉ số này được thu thập và trình bày riêng biệt cho từng volume NVMe riêng lẻ có sẵn trên một instance.\nCác thống kê được trình bày dưới ba định dạng chính:\nCác thống kê được trình bày dưới ba định dạng chính: Độ dài hàng đợi thời gian thực, hiển thị giá trị hiện tại tại thời điểm bạn truy vấn Biểu đồ phân phối độ trễ trực quan hóa sự phân bố của các hoạt động IO trên các phạm vi độ trễ khác nhau bằng cách hiển thị cả chế độ xem tích lũy và phân bố cụ thể theo kích thước IO Điều kiện tiên quyết Để truy cập thống kê hiệu năng chi tiết cho bộ lưu trữ instance cục bộ, hãy hoàn thành các bước sau:\nKhởi chạy một instance Amazon EC2 Nitro mới hoặc sử dụng một instance hiện có, sau đó kết nối với nó bằng SSH hoặc phương thức kết nối ưa thích của bạn. Xác định thiết bị NVMe liên kết với bộ lưu trữ cục bộ để truy vấn thống kê hiệu năng. Ví dụ, bạn có thể chạy lệnh nvme-cli trong CLI để xuất ra tất cả các thiết bị NVMe trên instance. bash $ sudo nvme list. Sau đây là ví dụ đầu ra của lệnh list liệt kê các thiết bị NVMe trên instance và Serial Numbers (SN) của volume (đã được che trong đầu ra bên dưới vì lý do riêng tư). Trong minh họa này, hãy coi rằng bộ lưu trữ cục bộ được ứng dụng của bạn sử dụng là /dev/nvme1n1.\nNếu bạn đang sử dụng Amazon Linux 2023 phiên bản 2023.8.20250915 (hoặc mới hơn) hoặc Amazon Linux 2 2.0.20251014.0 (hoặc mới hơn), bạn có thể chuyển sang Bước 4 vì nvme-cli sẽ sử dụng phiên bản mới nhất. Nếu bạn đang sử dụng phiên bản Amazon Linux cũ hơn, hãy cập nhật nvme-cli bằng lệnh sau, trong đó 2023.8.20250915 có thể được thay thế bằng phiên bản Amazon Linux 2023 mới nhất: bash $ sudo dnf upgrade --releasever=2023.8.20250915 Chạy nvme-cli, với các quyền chính xác, và truyền thiết bị như một tham số. Bạn có thể sử dụng --help để xem chi tiết về cách sử dụng lệnh: bash $ sudo nvme amzn stats --help Ví dụ đầu ra:\nNếu bạn thích đầu ra ở định dạng JSON, bạn có thể cung cấp tham số -o json cho lệnh.\nbash $ sudo nvme amzn stats /dev/nvme1n1 -o json Đầu ra sau đây (không có tham số -o json) hiển thị các hoạt động đọc/ghi tích lũy, số byte đọc/ghi, tổng thời gian xử lý (đọc và ghi tính bằng micro giây), và thời lượng (tính bằng micro giây) khi ứng dụng cố gắng vượt quá giới hạn IOPS/thông lượng của instance.\nNó cũng hiển thị các biểu đồ phân phối độ trễ I/O đọc/ghi, với mỗi hàng đại diện cho các hoạt động I/O đã hoàn thành trong một khoảng thời gian cụ thể (tính bằng micro giây).\nNếu bạn muốn xem các biểu đồ phân phối độ trễ trên 5 dải IO khác nhau: (0, 512 Byte], (512B, 4KiB], (4KiB, 8KiB], (8KiB 32KiB], (32 KiB, MAX], bạn có thể cung cấp tham số --details hoặc -d cho lệnh:\nbash $ sudo nvme amzn stats -d /dev/nvme1n Hình ảnh sau đây là một đoạn trích từ đầu ra của lệnh trên, hiển thị các biểu đồ phân phối độ trễ bổ sung (đọc và ghi) của 5 dải IO khác nhau.\nBạn có thể chạy lệnh stats ở độ chi tiết theo từng giây. Bạn cũng có thể viết script để lấy các thống kê theo khoảng thời gian mong muốn (mỗi giây hoặc bất kỳ thời lượng nào khác) với mỗi đầu ra tiếp theo phản ánh tổng số tích lũy cập nhật cho các chỉ số. Tính toán sự khác biệt trong các thống kê qua hai đầu ra cuối cùng cho phép bạn rút ra thông tin chi tiết về hồ sơ lưu trữ instance trong khoảng thời gian đó. Dưới đây là một script mẫu bạn có thể sử dụng để lấy các thống kê ở khoảng thời gian mặc định là 1 giây hoặc ở khoảng thời gian mong muốn của bạn.\n#!/bin/bash # interval of 1 second INTERVAL=${1:-1} while true; do echo \u0026#34;=== $(date) ===\u0026#34; sudo nvme amzn stats /dev/nvme1 || break echo sleep $INTERVAL done Bạn có thể lưu script này, cấp quyền thực thi và chạy nó ở khoảng thời gian mặc định 1 giây hoặc cung cấp một khoảng thời gian tùy chỉnh khi thực thi script. Ví dụ, nếu bạn đã lưu script là nvme_stats.sh, bạn có thể sử dụng các lệnh sau để cấp quyền thực thi và chạy để lấy đầu ra ở khoảng thời gian mặc định 1 giây (giả sử bạn đang ở cùng thư mục với nvme_stats.sh).\nchmod +x nvme_stats.sh ./nvme_stats.sh Nếu, chẳng hạn, bạn muốn lấy đầu ra mỗi 5 giây, bạn có thể sử dụng lệnh bên dưới (sau khi cấp quyền thực thi cho script)\n./nvme_stats.sh 5 Bạn cũng có thể tích hợp với CloudWatch bằng cách sử dụng CloudWatch agent để thu thập và xuất bản các thống kê này để theo dõi lịch sử, trực quan hóa xu hướng thông qua dashboard, và các cảnh báo dựa trên hiệu năng để tương quan với các chỉ số ứng dụng và thông báo tự động cho các vấn đề hiệu năng.\nRút ra thông tin chi tiết từ thống kê hiệu năng chi tiết NVMe instance store của Amazon EC2 Tương tự như thống kê hiệu năng chi tiết của EBS, bạn có thể sử dụng thống kê NVMe instance store của Amazon EC2 để khắc phục các vấn đề hiệu năng workload khác nhau. Như đã đề cập trong phần trước, bạn cũng có thể sử dụng các thống kê chi tiết để xem các biểu đồ phân phối độ trễ I/O nhằm quan sát sự phân tán của độ trễ I/O trong khoảng thời gian đó. Bạn có thể sử dụng các thống kê hoạt động đọc/ghi và thời gian đã sử dụng để tính toán độ trễ trung bình. Các thống kê chi tiết hiển thị độ trễ trung bình ở độ chi tiết theo từng giây.\nHai kịch bản ví dụ tiếp theo minh họa phân tích hiệu năng chính bằng cách sử dụng các thống kê. Trong Kịch bản 1, chúng ta sẽ sử dụng chỉ số EC2 Instance Local Storage Performance Exceeded (us) để kiểm tra xem nhu cầu I/O có vượt quá khả năng lưu trữ của instance hay không, giúp định cỡ instance phù hợp cho hiệu năng ứng dụng I/O đầy đủ. Trong Kịch bản 2, chúng ta sẽ sử dụng các biểu đồ phân phối cụ thể theo kích thước IO (sử dụng --details) để chẩn đoán cách các ghi khối lớn ảnh hưởng đến hiệu năng đọc tiếp theo – một vấn đề thường bị ẩn bởi các số liệu tổng hợp của các công cụ giám sát truyền thống trên tất cả các kích thước IO.\nKịch bản 1: Xác định khi các ứng dụng vượt quá giới hạn hiệu năng lưu trữ instance Hiểu liệu nhu cầu I/O của ứng dụng của bạn có vượt quá khả năng của các volume instance store hay không là điều quan trọng để khắc phục sự cố hiệu năng. Khi các ứng dụng tạo ra các workload I/O liên tục cố gắng vượt quá giới hạn IOPS và thông lượng của các loại instance Amazon EC2 cụ thể, bạn sẽ gặp phải độ trễ tăng cao và hiệu năng bị suy giảm. Chỉ số EC2 Instance Local Storage Performance Exceeded (us) giúp xác định các kịch bản này bằng cách hiển thị thời lượng (tính bằng micro giây) khi các workload vượt quá hiệu năng instance được hỗ trợ. Giá trị khác không hoặc số lượng tăng lên giữa các ảnh chụp nhanh (snapshot) cho thấy kích thước hoặc loại instance hiện tại của bạn có thể không cung cấp đủ hiệu năng I/O cho ứng dụng của bạn.\nPhần sau đây chỉ ra cách xác định xem một ứng dụng có đang gửi nhiều IOPS hơn mức bộ lưu trữ cục bộ của instance có thể hỗ trợ hay không.\nKịch bản ví dụ: Một ứng dụng trên instance i3en.xlarge hiển thị độ trễ ghi tăng cao \u0026gt;1ms. Bạn muốn xác định xem workload của ứng dụng có đang vượt quá hiệu năng được hỗ trợ của volume NVMe instance hay không.\nChọn thiết bị NVMe Instance Storage bạn muốn phân tích – Xác định instance bạn muốn phân tích cho ứng dụng đang gặp phải độ trễ tăng cao. Xác định thiết bị NVMe – Sử dụng lệnh nvme-cli sau, và xác định thiết bị NVMe liên kết với bộ lưu trữ instance đó. $ sudo nvme list Kịch bản ví dụ: Chúng tôi đã sử dụng lệnh list và xác định /dev/nvme1n1 là thiết bị NVMe liên kết với instance i3en.xlarge đang chạy ứng dụng hiện đang thấy độ trễ ghi tăng cao \u0026gt;1ms (trong khi độ trễ đọc là \u0026lt;50us theo điều kiện bình thường), vì vậy bây giờ chúng tôi muốn phân tích nó.\nThu thập thống kê cho thiết bị tại một thời điểm hoặc tại các khoảng thời gian mong muốn – Thu thập các thống kê hiệu năng chi tiết bằng lệnh nvme-cli hoặc sử dụng script mẫu được cung cấp trong phần trước để nắm bắt thống kê tại các khoảng thời gian mong muốn, nếu cần. $ sudo nvme amzn stats /dev/nvme1n1 Kịch bản ví dụ: Chúng tôi chọn thu thập thống kê chỉ một lần sau khi nhận thấy độ trễ ghi tăng cao của ứng dụng.\nPhân tích các thống kê để kiểm tra xem ứng dụng có yêu cầu nhiều hơn hiệu năng được hỗ trợ của bộ lưu trữ instance hay không – Xác nhận sự tồn tại của sự suy giảm độ trễ I/O tổng thể bằng cách so sánh hai bộ biểu đồ phân phối độ trễ I/O đọc/ghi được thực hiện cách nhau một khoảng thời gian. Kịch bản ví dụ: Đầu ra sau đây hiển thị biểu đồ phân phối Read IO của bộ lưu trữ instance cục bộ NVMe được thực hiện cách nhau 40 giây không có vấn đề về độ trễ read IO (vì độ trễ đọc bình thường cho workload này là \u0026lt; 50 us). Chỉ số được ghi lại tại thời điểm T:\nChỉ số được ghi lại tại thời điểm T+40s:\nĐầu ra sau đây hiển thị biểu đồ phân phối Write IO được thực hiện cách nhau 40 giây. Chúng ta có thể nhận thấy rằng nhiều write IO rơi vào phạm vi độ trễ 1ms – 2ms, điều này không được mong đợi cho ứng dụng này.\nChỉ số được ghi lại tại thời điểm T:\nChỉ số được ghi lại tại thời điểm T+40s:\nPhân tích chỉ số EC2 Instance Local Storage Performance Exceeded (us) hiển thị tổng thời gian (tính bằng micro giây) các yêu cầu IOPS vượt quá giới hạn volume. Lý tưởng nhất, số lượng tăng thêm của chỉ số này giữa hai thời điểm snapshot nên là tối thiểu, vì bất kỳ giá trị nào trên 0 đều chỉ ra rằng workload yêu cầu nhiều IOPS hơn mức volume có thể cung cấp. Kịch bản ví dụ: So sánh các chỉ số cách nhau 40 giây cho thấy rằng trong hơn 34 giây, nhu cầu IOPS của ứng dụng đã vượt qua IOPS được hỗ trợ bởi bộ lưu trữ instance cục bộ. Điều này giải thích độ trễ ghi tăng cao: IOPS dư thừa trên mức bộ lưu trữ cơ bản có thể xử lý vật lý sẽ xếp hàng các hoạt động, làm tăng thời gian chờ. Điều này chỉ ra rằng instance i3en.xlarge được chọn để chạy ứng dụng này không thể đáp ứng các yêu cầu hiệu năng của ứng dụng, gợi ý việc nâng cấp lên kích thước instance lớn hơn hoặc đánh giá lại chính loại instance đó. Chỉ số được ghi lại tại thời điểm T:\nChỉ số được ghi lại tại thời điểm T+40s:\nĐiều quan trọng là phải có kích thước instance phù hợp để tránh các điểm nghẽn hiệu năng cho ứng dụng của bạn. Tham khảo tài liệu về instance Amazon EC2 để biết thêm thông tin về các instance khác nhau và kích thước lưu trữ của chúng.\nKịch bản 2: Xác định kích thước khối gây ra độ trễ tăng cao trong các ứng dụng của bạn Nhiều vấn đề hiệu năng lưu trữ phát sinh từ các tương tác phức tạp giữa các hoạt động đọc và ghi với các kích thước I/O khác nhau, mà các công cụ giám sát cấp hệ thống truyền thống như iostat hoặc sar không thể chẩn đoán hiệu quả do các số liệu tổng hợp của chúng trên tất cả các kích thước I/O. Thống kê hiệu năng chi tiết NVMe instance store EC2 giải quyết vấn đề này bằng cách cung cấp các biểu đồ phân phối độ trễ cụ thể theo kích thước I/O thông qua tùy chọn --details trong NVMe CLI. Các biểu đồ phân phối này hiển thị dữ liệu độ trễ cho các phạm vi kích thước I/O khác nhau: (0, 512 Byte], (512B, 4KiB], (4KiB, 8KiB], (8KiB, 32KiB], (32KiB, MAX], cho phép tương quan chính xác hơn giữa các mẫu workload ứng dụng và các chỉ số độ trễ cụ thể theo kích thước I/O để tối ưu hóa có mục tiêu.\nTrong kịch bản ví dụ này, ứng dụng của bạn thực hiện các lần đọc nhỏ (thường \u0026lt;=4KiB, như đọc metadata) theo sau là các lần ghi lớn (\u0026gt;=32KiB) và hiển thị độ trễ đọc cao bất ngờ. Vấn đề phổ biến này xảy ra khi các lần ghi lớn ảnh hưởng đến hiệu năng của các hoạt động đọc tiếp theo, tạo ra hiệu ứng dây chuyền lên hiệu năng I/O tổng thể.\nThu thập độ trễ IO đọc và ghi theo phạm vi kích thước – Sử dụng NVMe CLI với tùy chọn --details để thu thập độ trễ IO đọc và ghi theo phạm vi kích thước: $ sudo nvme amzn stats /dev/nvme1n1 --details Xác nhận sự tồn tại của sự suy giảm độ trễ IO tổng thể – Trong kịch bản ví dụ, kiểm tra độ trễ IO tổng thể, cả hoạt động đọc (trái) và ghi (phải) đều đang hiển thị độ trễ cao hơn mong đợi. Kiểm tra đầu ra cho các mẫu trên các dải kích thước IO khác nhau – Phân tích độ trễ theo kích thước hoạt động cho thấy các hoạt động đọc nhỏ (512 byte đến 4K), thường nhanh, đang gặp phải các đợt tăng độ trễ bất ngờ trong khi các lần ghi lớn (32K+) hiển thị sự chậm trễ đáng kể. Các lần đọc nhỏ về lý thuyết nên duy trì hiệu năng tốt bất kể các hoạt động I/O khác. Mẫu quan sát được chỉ ra rằng các hoạt động ghi lớn bị ứ đọng tạo ra sự tắc nghẽn toàn hệ thống, ảnh hưởng đến tất cả các hoạt động I/O thuộc mọi loại và kích thước. Mặc dù khả năng của hệ thống lưu trữ để xử lý các lần đọc nhỏ một cách hiệu quả, các lần ghi lớn đang xếp hàng làm chậm cả hoạt động đọc và ghi ở cấp độ ứng dụng.\nDựa trên phân tích này, chúng ta có thể thực hiện một số tối ưu hóa có mục tiêu cho ứng dụng, như sử dụng kích thước khối nhỏ hơn cho các hoạt động ghi khi có thể, hoặc gộp các lần ghi nhỏ thay vì thực hiện các lần ghi đơn lẻ lớn.\nDọn dẹp Nếu bạn đã tạo một instance Amazon EC2 với volume NVMe cho bài tập này, hãy chấm dứt và xóa instance thích hợp để tránh chi phí trong tương lai.\nKết luận Thống kê hiệu năng chi tiết của Amazon EC2 cho instance store volume NVMe cung cấp giám sát hiệu năng lưu trữ thời gian thực, dưới một phút, tương tự như thống kê hiệu năng chi tiết có sẵn cho các volume Amazon EBS. Điều này cung cấp trải nghiệm giám sát nhất quán trên cả hai loại lưu trữ, với các biểu đồ phân phối độ trễ dựa trên kích thước IO bổ sung cho bộ lưu trữ instance để tối ưu hóa tốt hơn các mẫu I/O, và khắc phục sự cố hiệu quả hơn.\nĐể tìm hiểu thêm về các volume NVMe instance store của Amazon EC2, các kỹ thuật tối ưu hóa cho các workload nhạy cảm với độ trễ hoặc các chủ đề liên quan đến Amazon EC2 khác, hãy truy cập trang tài liệu Amazon EC2 hoặc khám phá các bài đăng khác trên AWS Storage Blog của chúng tôi về tối ưu hóa hiệu năng.\nChúng tôi rất muốn nghe cách bạn đang sử dụng các thống kê này để nâng cao workload của mình, hoặc nếu bạn có bất kỳ câu hỏi nào, trong phần bình luận bên dưới.\n"},{"uri":"https://vdhxi.github.io/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Cách xuất dữ liệu sang Amazon S3 Tables bằng cách sử dụng AWS Step Functions Distributed Map Các công ty chạy khối lượng công việc serverless thường cần thực hiện các hoạt động trích xuất, chuyển đổi và tải (ETL) trên các tệp dữ liệu được lưu trữ trong các bucket Amazon Simple Storage Service (Amazon S3). Mặc dù các phương pháp truyền thống như AWS Lambda trigger cho Amazon S3 hoặc Amazon S3 Event Notifications có thể xử lý các hoạt động này, chúng có thể không đáp ứng được khi quy trình làm việc yêu cầu khả năng hiển thị, kiểm soát hoặc sự can thiệp của con người nâng cao. Ví dụ, một số quy trình có thể cần xem xét thủ công các bản ghi bị lỗi hoặc phê duyệt rõ ràng trước khi chuyển sang các giai đoạn tiếp theo. Các giải pháp điều phối tùy chỉnh cho những vấn đề này có thể trở nên phức tạp và dễ xảy ra lỗi.\nAWS Step Functions giải quyết những thách thức này bằng cách cung cấp khả năng quản lý và giám sát quy trình làm việc tích hợp. Tính năng Step Functions Distributed Map được thiết kế cho các quy trình xử lý dữ liệu song song, thông lượng cao để các công ty có thể xử lý các công việc ETL phức tạp, xử lý fan-out và trực quan hóa dữ liệu ở quy mô lớn. Distributed Map xử lý từng mục dữ liệu như một quy trình làm việc con độc lập, xử lý hàng triệu bản ghi trong khi vẫn duy trì các kiểm soát đồng thời tích hợp, khả năng chịu lỗi và theo dõi tiến độ. Dữ liệu đã xử lý có thể được xuất liền mạch đến nhiều đích khác nhau, bao gồm Amazon S3 Tables với hỗ trợ Apache Iceberg.\nTrong bài viết này, chúng tôi chỉ ra cách sử dụng Step Functions Distributed Map để xử lý các đối tượng Amazon S3 và xuất kết quả sang Amazon S3 Tables, tạo ra một đường ống xử lý dữ liệu có thể mở rộng và dễ bảo trì.\nXem GitHub repository liên quan để biết hướng dẫn chi tiết về việc triển khai giải pháp này cũng như mã mẫu.\nTổng quan giải pháp Hãy xem xét một công ty điện tử tiêu dùng thường xuyên tham gia các triển lãm thương mại và hội nghị trong ngành. Trong các sự kiện này, những người tham dự quan tâm điền vào các biểu mẫu đăng ký bằng giấy để yêu cầu demo sản phẩm, nhận bản tin hoặc tham gia các chương trình truy cập sớm. Sau các sự kiện, đội ngũ của công ty quét hàng trăm nghìn biểu mẫu này và tải chúng lên Amazon S3. Thay vì xem xét thủ công từng biểu mẫu, công ty muốn tự động hóa việc trích xuất các chi tiết khách hàng chính như tên, địa chỉ email, địa chỉ gửi thư và các lĩnh vực quan tâm. Họ muốn lưu trữ dữ liệu có cấu trúc này trong S3 Tables với định dạng Apache Iceberg cho các phân tích downstream và nhắm mục tiêu chiến dịch tiếp thị.\nHãy xem cách giải pháp của bài viết này sử dụng Distributed Map để xử lý các tệp PDF song song, trích xuất dữ liệu bằng Amazon Textract và ghi đầu ra đã làm sạch trực tiếp vào S3 Tables. Kết quả là quá trình onboard dữ liệu sau sự kiện có thể mở rộng, không máy chủ, như được hiển thị trong hình sau.\nQuy trình xử lý dữ liệu như được hiển thị trong sơ đồ trước bao gồm các bước sau:\nNgười dùng tải các biểu mẫu quan tâm của khách hàng dưới dạng PDF đã quét lên một bucket Amazon S3. Một quy tắc Amazon EventBridge Scheduler kích hoạt theo các khoảng thời gian đều đặn, bắt đầu thực thi quy trình làm việc Step Functions. Việc thực thi quy trình làm việc kích hoạt trạng thái Step Functions Distributed Map, liệt kê tất cả các tệp PDF đã tải lên Amazon S3 kể từ lần chạy trước. Distributed Map lặp qua danh sách các đối tượng và chuyển metadata của từng đối tượng (bucket, key, size, entity tag [ETag]) cho một thực thi quy trình làm việc con. Đối với mỗi đối tượng, quy trình làm việc con gọi Amazon Textract với bucket và key được cung cấp để trích xuất văn bản thô và các trường liên quan (tên, địa chỉ email, địa chỉ gửi thư, lĩnh vực quan tâm) từ PDF. Quy trình làm việc con gửi dữ liệu đã trích xuất đến Amazon Data Firehose, được cấu hình để chuyển tiếp dữ liệu đến S3 Tables. Firehose phân lô dữ liệu đến từ quy trình làm việc con và ghi nó vào S3 Tables theo khoảng thời gian được cấu hình trước mà bạn chọn. Với dữ liệu hiện đã được cấu trúc và có thể truy cập trong S3 Tables, người dùng có thể dễ dàng phân tích chúng bằng các truy vấn SQL tiêu chuẩn với Amazon Athena hoặc trí tuệ doanh nghiệp như Amazon QuickSight.\nQuy trình xử lý dữ liệu EventBridge Scheduler bắt đầu các quy trình làm việc Step Functions mới theo các khoảng thời gian đều đặn. Dòng thời gian cho lịch trình này rất linh hoạt. Tuy nhiên, khi thiết lập lịch trình của bạn, hãy đảm bảo tần suất phù hợp với khoảng thời gian mà state machine của bạn được cấu hình để tìm kiếm các tệp PDF. Ví dụ: nếu state machine của bạn kiểm tra các tệp PDF từ tuần trước, bạn sẽ muốn lên lịch chạy hàng tuần. Quy trình làm việc Step Functions sau đó thực hiện ba bước sau (lưu ý rằng các bước này là các bước 4, 5, 6 và 7 trong sơ đồ quy trình làm việc trước đó):\nTrích xuất dữ liệu người dùng liên quan từ các tệp PDF. Gửi dữ liệu người dùng đã trích xuất đến Firehose. Ghi dữ liệu vào S3 Tables ở định dạng bảng Apache Iceberg. Sơ đồ sau minh họa quy trình làm việc này.\nHãy xem xét từng bước của quy trình làm việc trước đó chi tiết hơn.\nTrích xuất dữ liệu người dùng liên quan từ tài liệu PDF Step Functions sử dụng Distributed Map để xử lý các tệp PDF đồng thời trong các quy trình làm việc con song song. Nó chấp nhận đầu vào từ JSON, JSONL, CSV, tệp Parquet, tệp kê khai Amazon S3 được lưu trữ trong Amazon S3 (được sử dụng để chỉ định các tệp cụ thể để xử lý) hoặc Amazon S3 bucket prefix (cho phép lặp qua metadata tệp cho tất cả các đối tượng dưới prefix đó). Step Functions tự động xử lý việc song song hóa bằng cách chia nhỏ tập dữ liệu và chạy các quy trình làm việc con cho từng mục, với trường ItemBatcher cho phép nhóm nhiều tệp PDF vào một lần thực thi quy trình làm việc con duy nhất (ví dụ: 10 tệp PDF mỗi lô) để tối ưu hóa hiệu suất và chi phí.\nẢnh chụp màn hình sau của bảng điều khiển Step Functions hiển thị cấu hình cho Distributed Map. Ví dụ: chúng tôi đã cấu hình Distributed Map để xử lý 10 tệp PDF quan tâm của khách hàng trong một quy trình làm việc con duy nhất.\nHình ảnh sau đây hiển thị một ví dụ về các tệp PDF được quét này, bao gồm thông tin khách hàng mà giải pháp của bài viết này xử lý.\nMỗi quy trình làm việc con sau đó gọi Amazon Textract AnalyzeDocument API với các truy vấn cụ thể để trích xuất thông tin khách hàng.\n{ \u0026#34;Document\u0026#34;: { \u0026#34;S3Object\u0026#34;: { \u0026#34;Bucket\u0026#34;: \u0026#34;\u0026lt;input PDFs bucket\u0026gt;\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;{% $states.input.Key %}\u0026#34; } }, \u0026#34;FeatureTypes\u0026#34;: [ \u0026#34;QUERIES\u0026#34; ], \u0026#34;QueriesConfig\u0026#34;: { \u0026#34;Queries\u0026#34;: [ { \u0026#34;Alias\u0026#34;: \u0026#34;full_name\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer\u0026#39;s name?\u0026#34; }, { \u0026#34;Alias\u0026#34;: \u0026#34;phone_number\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer’s phone number?\u0026#34; }, { \u0026#34;Alias\u0026#34;: \u0026#34;mailing_address\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer’s mailing address?\u0026#34; }, { \u0026#34;Alias\u0026#34;: \u0026#34;interest\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer’s interest?\u0026#34; } ] } } API phân tích từng tệp PDF được quét và trả về cấu trúc JSON chứa thông tin khách hàng đã trích xuất.\nGửi dữ liệu người dùng đã trích xuất đến Firehose Quy trình làm việc con sau đó sử dụng hành động Firehose PutRecordBatch API với tích hợp dịch vụ để xếp hàng thông tin khách hàng đã trích xuất để xử lý thêm. Yêu cầu hành động PutRecordBatch bao gồm tên luồng Firehose và các bản ghi dữ liệu. Các bản ghi dữ liệu bao gồm một blob dữ liệu từ bước 1 chứa thông tin khách hàng đã trích xuất, như được hiển thị trong ví dụ sau.\n{ \u0026#34;DeliveryStreamName\u0026#34;: \u0026#34;put_raw_form_data_100\u0026#34;, \u0026#34;Records\u0026#34;: [ { \u0026#34;Data\u0026#34;: \u0026#34;{\\\u0026#34;full_name\\\u0026#34;:\\\u0026#34;Anthony Ayala\\\u0026#34;,\\\u0026#34;phone_number\\\u0026#34;:\\\u0026#34;001-384-925-0701\\\u0026#34;,\\\u0026#34;mailing_address\\\u0026#34;:\\\u0026#34;38548 Joshua Wall Suite 974, East Heatherfort, OH 32669\\\u0026#34;,\\\u0026#34;interest\\\u0026#34;:\\\u0026#34;Fitness Trackers\\\u0026#34;,\\\u0026#34;processed_date\\\u0026#34;:\\\u0026#34;2025-05-01\\\u0026#34;}\u0026#34; }, { \u0026#34;Data\u0026#34;: \u0026#34;{\\\u0026#34;full_name\\\u0026#34;:\\\u0026#34;Becky Williams\\\u0026#34;,\\\u0026#34;phone_number\\\u0026#34;:\\\u0026#34;+1-283-499-2466\\\u0026#34;,\\\u0026#34;mailing_address\\\u0026#34;:\\\u0026#34;227 King Forge Suite 241, East Nathanland, PR 05687\\\u0026#34;,\\\u0026#34;interest\\\u0026#34;:\\\u0026#34;Al Assistants\\\u0026#34;,\\\u0026#34;processed_date\\\u0026#34;:\\\u0026#34;2025-05-01\\\u0026#34;}\u0026#34; } ] } Ghi dữ liệu vào S3 Tables ở định dạng bảng Apache Iceberg Firehose quản lý hiệu quả việc đệm dữ liệu, chuyển đổi định dạng và phân phối đáng tin cậy đến nhiều đích khác nhau, bao gồm Apache Iceberg, tệp thô trong Amazon S3, Amazon OpenSearch Service, hoặc bất kỳ đích nào khác được hỗ trợ. Các bảng Apache Iceberg có thể được tự quản lý trong Amazon S3 hoặc được lưu trữ trong S3 Tables. Mặc dù các bảng Iceberg tự quản lý yêu cầu tối ưu hóa thủ công—chẳng hạn như nén và hết hạn snapshot—S3 Tables tự động tối ưu hóa lưu trữ cho khối lượng công việc phân tích quy mô lớn, cải thiện hiệu suất truy vấn và giảm chi phí lưu trữ.\nFirehose đơn giản hóa quá trình truyền dữ liệu bằng cách cấu hình luồng phân phối, chọn nguồn dữ liệu và đặt bảng Iceberg làm đích. Sau khi bạn thiết lập xong, luồng Firehose đã sẵn sàng để phân phối dữ liệu. Dữ liệu được phân phối có thể được truy vấn từ S3 Tables bằng cách sử dụng Athena, như được hiển thị trong ảnh chụp màn hình sau của bảng điều khiển Athena.\nKết quả truy vấn bao gồm tất cả dữ liệu khách hàng đã xử lý từ các tệp PDF, như được hiển thị trong ảnh chụp màn hình sau.\nSự tích hợp này thể hiện một giải pháp mạnh mẽ, không cần mã để chuyển đổi các biểu mẫu PDF thô thành dữ liệu có thể truy vấn, phong phú trong bảng Iceberg. Bạn có thể sử dụng dữ liệu này để phân tích thêm.\nKết luận Trong bài viết này, chúng tôi đã chỉ ra cách xây dựng một giải pháp có thể mở rộng, không máy chủ để xử lý tài liệu PDF và xuất dữ liệu đã trích xuất sang S3 Tables bằng cách sử dụng Step Functions Distributed Map. Kiến trúc này mang lại một số lợi ích chính như độ tin cậy, hiệu quả chi phí, khả năng hiển thị và khả năng bảo trì. Bằng cách tận dụng các dịch vụ AWS như Step Functions, Amazon Textract, Firehose và S3 Tables, các công ty có thể tự động hóa quy trình xử lý tài liệu của họ trong khi đảm bảo hiệu suất tối ưu và sự xuất sắc trong vận hành. Giải pháp này có thể được điều chỉnh cho nhiều trường hợp sử dụng khác ngoài các biểu mẫu quan tâm của khách hàng, chẳng hạn như xử lý hóa đơn, biểu mẫu đăng ký hoặc bất kỳ kịch bản nào yêu cầu trích xuất dữ liệu có cấu trúc từ tài liệu ở quy mô lớn.\nMặc dù ví dụ này tập trung vào việc xử lý dữ liệu PDF và ghi vào S3 Tables, Distributed Map có thể xử lý nhiều nguồn đầu vào khác nhau bao gồm JSON, JSONL, CSV và tệp Parquet trong Amazon S3; các mục trong bảng Amazon DynamoDB; kết quả truy vấn Athena; và tất cả các AWS List API được phân trang. Tương tự, thông qua tích hợp dịch vụ Step Functions, bạn có thể ghi kết quả đến nhiều đích như bảng DynamoDB bằng cách sử dụng tích hợp dịch vụ PutItem.\nĐể bắt đầu với giải pháp này, hãy xem GitHub repository liên quan để biết hướng dẫn triển khai và mã mẫu.\n"},{"uri":"https://vdhxi.github.io/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":"DISA STIG cho Amazon Linux 2023 hiện đã có sẵn Hôm nay, chúng tôi thông báo về sự sẵn có của Hướng dẫn Triển khai Kỹ thuật Bảo mật (STIG) cho Amazon Linux 2023 (AL2023), được phát triển thông qua sự hợp tác giữa Amazon Web Services (AWS) và Cơ quan Hệ thống Thông tin Quốc phòng (DISA). Các hướng dẫn STIG rất quan trọng đối với Bộ Quốc phòng Hoa Kỳ (DOD) và các khách hàng Liên bang cần tuân thủ bảo mật nghiêm ngặt bắt nguồn từ Viện Tiêu chuẩn và Công nghệ Quốc gia (NIST) 800-53 và các tài liệu liên quan. Hướng dẫn triển khai kỹ thuật mới này cung cấp các cấu hình làm cứng (hardening) bảo mật Hệ điều hành (OS) chi tiết cho các tổ chức triển khai AL2023 trong môi trường DOD và các cơ quan khác yêu cầu sự phù hợp với DISA STIG. AL2023 STIG cung cấp cho khách hàng quyền truy cập vào hướng dẫn OS tuân thủ các tiêu chuẩn bảo mật nghiêm ngặt của chính phủ. Hướng dẫn này để triển khai các cấu hình STIG sẽ hợp lý hóa các quy trình bảo mật cho các tổ chức đang tìm kiếm các biện pháp kiểm soát an ninh mạng mạnh mẽ, cho dù họ cần duy trì sự tuân thủ DOD hay tự nguyện áp dụng các thực tiễn bảo mật tốt nhất này để nâng cao vị thế bảo mật của họ.\nTriển khai AL2023 DISA STIG với AWS AWS Systems Manager (SSM) và EC2 Image Builder cung cấp các giải pháp gốc để triển khai các cấu hình AL2023 DISA STIG trong môi trường của bạn. Đối với các khách hàng có khối lượng công việc AL2023 EC2 hiện có, họ có thể sử dụng AWS Systems Manager (SSM) để hợp lý hóa việc triển khai STIG. Đối với các khách hàng muốn xây dựng các instance AL2023 EC2 tuân thủ STIG để sử dụng cho việc triển khai, họ có thể sử dụng EC2 Image Builder và tự động hóa việc áp dụng AL2023 DISA STIG.\nXây dựng các Image tuân thủ STIG thông qua EC2 Image Builder Khách hàng có thể sử dụng EC2 Image Builder để nâng cao và hợp lý hóa việc triển khai AL2023 DISA STIG của họ. Cách tiếp cận tích hợp này làm giảm đáng kể chi phí vận hành thường liên quan đến việc duy trì sự tuân thủ STIG. Do đó, khách hàng của chúng tôi có thể tập trung vào các nhiệm vụ cốt lõi của họ trong khi vẫn duy trì các tiêu chuẩn bảo mật cao nhất. Khách hàng của chúng tôi có thể sử dụng các thành phần làm cứng Linux hiện có của AWS EC2 Image Builder, hiện hỗ trợ các phát hiện AL2023 Category I, II và III để tự động tạo các image AL2023 EC2 tuân thủ STIG với sự can thiệp thủ công tối thiểu. Sự tự động hóa này làm giảm đáng kể thời gian và công sức thường cần thiết cho việc triển khai làm cứng bảo mật. Thành phần làm cứng Linux của EC2 Image Builder mở rộng các khả năng đã được chứng minh của nó cho AL2023, cung cấp quy trình cấu hình bảo mật hợp lý tương tự có sẵn cho các bản phân phối Linux khác. Để biết thêm thông tin, hãy tham khảo tài liệu Image Builder.\nTự động hóa STIG cho các đội tàu hiện có thông qua Systems Manager Đối với các instance AL2023 EC2 hiện có, bạn có thể sử dụng các tài liệu lệnh SSM do AWS quản lý để tự động hóa việc triển khai các cấu hình STIG. Các tài liệu lệnh này có thể được thực thi thông qua bảng điều khiển SSM, API hoặc Giao diện dòng lệnh AWS (AWS CLI). Cơ chế chính ở đây là tài liệu lệnh Systems Manager do AWS quản lý, chứa các cấu hình STIG được xác định trước. Bằng cách tận dụng các tài liệu lệnh này thông qua các khả năng thực thi của Systems Manager, khách hàng có thể triển khai và duy trì một cách có hệ thống các cấu hình AL2023 STIG trên toàn bộ đội tàu instance EC2 của họ. Điều này tạo ra các đường cơ sở bảo mật nhất quán đáp ứng các yêu cầu của chính phủ và doanh nghiệp. Giải pháp này đặc biệt hiệu quả đối với các môi trường có các instance AL2023 EC2 hiện có vì nó cho phép khách hàng thực hiện các biện pháp kiểm soát STIG mà không cần xây dựng lại hoặc triển khai lại các instance. Để biết thêm thông tin về tài liệu lệnh, hãy tham khảo Áp dụng cài đặt STIG với Systems Manager trong Hướng dẫn sử dụng EC2.\nAL2023 STIG đại diện cho cam kết liên tục của Amazon Linux trong việc cung cấp cho khách hàng các công cụ và hướng dẫn bảo mật mà họ cần để thành công trong các môi trường được quy định chặt chẽ. Amazon Linux, phối hợp với DISA đang cung cấp cho khách hàng của họ quyền truy cập vào các cấu hình bảo mật có thẩm quyền, được chính phủ xác nhận đáp ứng các yêu cầu tuân thủ khắt khe nhất.\nSẵn sàng triển khai AL2023 STIG trong môi trường của bạn? Khám phá tài liệu toàn diện của chúng tôi và bắt đầu hành trình hợp lý hóa sự tuân thủ bảo mật của bạn ngay hôm nay. Để tìm hiểu thêm về làm cứng STIG cho các instance EC2 của bạn, hãy tham khảo Tuân thủ STIG cho instance EC2 của bạn và đối với các cài đặt STIG được áp dụng cho các instance EC2 Linux, hãy tham khảo cài đặt STIG cho các instance EC2 Linux. Để áp dụng cài đặt STIG cho instance AL 2023 EC2 của bạn, tải xuống AL2023 DISA STIG.\n"},{"uri":"https://vdhxi.github.io/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":"Kiến tạo sự xuất sắc của AI: AWS ra mắt ba Well-Architected Lenses tại re:Invent 2025 Tại re:Invent 2025, chúng tôi giới thiệu một lens mới và hai bản cập nhật quan trọng cho AWS Well-Architected Lenses tập trung đặc biệt vào các workload AI: Responsible AI Lens, Machine Learning (ML) Lens, và Generative AI Lens. Cùng với nhau, các lens này cung cấp hướng dẫn toàn diện cho các tổ chức ở các giai đoạn khác nhau trong hành trình AI của họ, cho dù bạn mới bắt đầu thử nghiệm với machine learning hay đã triển khai các ứng dụng AI phức tạp ở quy mô lớn.\nAWS Well-Architected Framework cung cấp các thực tiễn kiến trúc tốt nhất để thiết kế và vận hành các workload tin cậy, an toàn, hiệu quả về hiệu năng, tối ưu hóa chi phí và bền vững trên đám mây.\nResponsible AI Lens: Nhúng niềm tin vào các hệ thống AI Responsible AI Lens cung cấp một cách tiếp cận có cấu trúc cho các nhà phát triển để đánh giá và theo dõi các workload AI của họ dựa trên các thực tiễn tốt nhất đã được thiết lập, xác định các lỗ hổng tiềm ẩn trong việc triển khai AI của họ và nhận hướng dẫn khả thi để cải thiện chất lượng và sự phù hợp của hệ thống AI với các nguyên tắc AI có trách nhiệm. Bằng cách sử dụng Responsible AI Lens, bạn có thể đưa ra các quyết định sáng suốt cân bằng giữa các yêu cầu kinh doanh và kỹ thuật, đẩy nhanh con đường từ thử nghiệm AI đến các giải pháp sẵn sàng cho sản xuất.\nNhững điểm chính từ Responsible AI Lens:\nMọi hệ thống AI đều có cân nhắc về Responsible AI: Cho dù được thiết kế có chủ ý hay không, các hệ thống AI vốn dĩ mang theo những tác động về Responsible AI cần được quản lý tích cực thay vì phó mặc cho may rủi. Các hệ thống AI có thể được sử dụng ngoài mục đích ban đầu và có thể có những tác động không mong muốn: Các ứng dụng thường được sử dụng theo những cách mà các nhà phát triển không lường trước được, và do bản chất xác suất của chúng, các hệ thống AI có thể tạo ra các kết quả bất ngờ ngay cả trong các trường hợp sử dụng đã định, khiến các quyết định Responsible AI mạnh mẽ trở nên cần thiết ngay từ đầu. Responsible AI là yếu tố thúc đẩy đổi mới và niềm tin: Thay vì là một sự ràng buộc, các thực tiễn Responsible AI có thể thúc đẩy đổi mới bằng cách chủ động xây dựng niềm tin của các bên liên quan và khách hàng và giảm thiểu rủi ro downstream. Responsible AI Lens đóng vai trò là hướng dẫn nền tảng cho các hoạt động phát triển AI, cung cấp các hướng dẫn quan trọng thông báo cho cả việc triển khai Machine Learning Lens và Generative AI Lens.\nMachine Learning Lens: Nền tảng cho các workload ML Machine Learning Lens cung cấp cho bạn một bộ các thực tiễn tốt nhất không phụ thuộc vào đám mây đã được thiết lập dưới dạng các trụ cột Well-Architected Framework cho từng giai đoạn vòng đời machine learning (ML). Machine Learning Lens được cập nhật cung cấp một cách tiếp cận nhất quán để thiết kế, xây dựng và vận hành các workload machine learning trên AWS. Nó giải quyết toàn bộ các workload ML, từ học có giám sát và không giám sát truyền thống đến các ứng dụng AI hiện đại.\nMachine Learning Lens được cập nhật kết hợp các khả năng AWS ML mới nhất (đã phát triển kể từ khi được giới thiệu vào năm 2023). Có gì mới trong ML Lens được cập nhật:\nCác quy trình làm việc cộng tác dữ liệu và AI được nâng cao thông qua Amazon SageMaker Unified Studio. Phát triển được hỗ trợ bởi AI để tạo mã và nâng cao năng suất. Cơ sở hạ tầng đào tạo phân tán để phát triển và tinh chỉnh mô hình nền tảng với Amazon SageMaker HyperPod. Các khả năng tùy chỉnh mô hình như chưng cất kiến thức và tinh chỉnh các ứng dụng cụ thể theo miền bằng cách sử dụng Amazon Bedrock với Kiro và Amazon Q Developer. Phát triển ML không cần mã (no-code) sử dụng Amazon SageMaker Canvas với tích hợp Amazon Q. Phát hiện thiên kiến được cải thiện với các chỉ số công bằng nâng cao và các khả năng Responsible AI trong Amazon SageMaker Clarify. Tạo bảng điều khiển tự động cho thông tin chi tiết về kinh doanh thông qua Amazon Quick Sight. Kiến trúc suy luận mô-đun để triển khai mô hình linh hoạt với Inference Components. Khả năng quan sát nâng cao với các khả năng gỡ lỗi và giám sát được cải thiện trong suốt vòng đời ML. Tối ưu hóa chi phí nâng cao cho quản lý tài nguyên thông qua Amazon SageMaker Training Plans, Savings Plans, và hỗ trợ Spot Instance. Bạn có thể sử dụng ML Lens bất kể bạn đang ở đâu trên hành trình đám mây của mình. Bạn có thể chọn áp dụng hướng dẫn này trong quá trình thiết kế các workload ML của mình hoặc sau khi các workload của bạn đã đi vào sản xuất như một phần của quy trình cải tiến liên tục. Những cải tiến này được hỗ trợ bởi các dịch vụ AWS chính bao gồm Amazon SageMaker Unified Studio, Amazon Q, Amazon SageMaker HyperPod, và Amazon Bedrock.\nGenerative AI Lens: Hướng dẫn chuyên biệt cho các mô hình nền tảng Generative AI Lens cung cấp một cách tiếp cận nhất quán cho khách hàng để đánh giá các kiến trúc sử dụng các mô hình ngôn ngữ lớn (LLM) để đạt được các mục tiêu kinh doanh của họ. Lens này giải quyết các cân nhắc chung liên quan đến lựa chọn mô hình, kỹ thuật prompt, tùy chỉnh mô hình, tích hợp workload và cải tiến liên tục. Chúng tôi xác định các thực tiễn tốt nhất giúp bạn kiến trúc các ứng dụng và workload dựa trên đám mây của mình theo các nguyên tắc thiết kế AWS Well-Architected được thu thập từ việc hỗ trợ hàng nghìn triển khai của khách hàng. Trong khi Machine Learning (ML) Lens bao gồm phạm vi rộng lớn của các workload ML, Generative AI Lens tập trung cụ thể vào các mô hình nền tảng và các ứng dụng generative AI. Generative AI Lens cung cấp các thực tiễn kiến trúc tốt nhất để thiết kế và vận hành các workload generative AI trên AWS.\nGenerative AI Lens được cập nhật bao gồm một số bổ sung mới:\nHướng dẫn Amazon SageMaker HyperPod để điều phối các quy trình làm việc generative AI phức tạp, chạy lâu dài bao gồm các khả năng dịch vụ bổ sung. Lời mở đầu về Responsible AI được nâng cao với thảo luận chi tiết về tám khía cạnh cốt lõi của Responsible AI như được mô tả bởi AWS. Lời mở đầu về kiến trúc dữ liệu được cập nhật với các cân nhắc chiến lược cần thiết để kiến trúc một hệ thống dữ liệu cho các workload generative AI. Lời mở đầu về agentic AI mới giới thiệu các mô hình kiến trúc cho các hệ thống agentic. Tám kịch bản kiến trúc bao gồm các ứng dụng kinh doanh được hỗ trợ bởi generative AI phổ biến như trung tâm cuộc gọi tự động, đồng nghiệp ảo cho nhân viên tri thức và các hệ thống dịch vụ generative AI đa thuê bao (multi-tenant). Generative AI Lens xây dựng dựa trên nền tảng được thiết lập bởi ML Lens, cung cấp hướng dẫn chuyên biệt cho những thách thức và cơ hội độc đáo được trình bày bởi các mô hình nền tảng và các ứng dụng generative AI.\nChiến lược triển khai cho hướng dẫn Well-Architected AI/ML: Một cách tiếp cận thống nhất Các lens mới – Responsible AI Lens, Machine Learning Lens, và Generative AI Lens – làm việc cùng nhau để cung cấp hướng dẫn toàn diện cho phát triển AI. Responsible AI Lens hướng dẫn phát triển AI an toàn, công bằng và bảo mật. Nó giúp cân bằng nhu cầu kinh doanh với các yêu cầu kỹ thuật, hợp lý hóa quá trình chuyển đổi từ thử nghiệm sang sản xuất. Machine Learning Lens hướng dẫn các tổ chức đánh giá các workload trên cả các phương pháp tiếp cận AI hiện đại và machine learning truyền thống. Các cập nhật gần đây tập trung vào các lĩnh vực chính bao gồm các quy trình làm việc cộng tác dữ liệu và AI được nâng cao, các khả năng phát triển được hỗ trợ bởi AI, cung cấp cơ sở hạ tầng quy mô lớn và triển khai mô hình có thể tùy chỉnh. Generative AI Lens giúp khách hàng đánh giá các kiến trúc dựa trên mô hình ngôn ngữ lớn (LLM) và các cập nhật của nó bao gồm hướng dẫn cho người dùng Amazon SageMaker HyperPod, thông tin chi tiết mới về agentic AI và các kịch bản kiến trúc được cập nhật.\nCác bước tiếp theo là gì? Việc ra mắt các lens mới này tại re:Invent 2025 giúp các tổ chức xây dựng các hệ thống AI có trách nhiệm, đáng tin cậy, mạnh mẽ và hiệu quả. Bằng cách cung cấp hướng dẫn toàn diện trên toàn bộ phạm vi của các workload AI, AWS hỗ trợ các tổ chức đẩy nhanh các sáng kiến AI của họ trong khi vẫn duy trì các tiêu chuẩn cao nhất về AI có trách nhiệm và sự xuất sắc về kỹ thuật.\nTìm hiểu thêm về AWS Well-Architected Framework và triển khai hướng dẫn thực tiễn tốt nhất được cung cấp bằng cách sử dụng GitHub repository. Các lens này là các công cụ thực tế được thiết kế để giúp bạn xây dựng các hệ thống AI mang lại giá trị kinh doanh thực sự trong khi vẫn duy trì các tiêu chuẩn cao nhất về đạo đức, bảo mật và sự xuất sắc trong vận hành.\nĐể đọc thêm, hãy tham khảo AWS Well-Architected Framework và các sách trắng về trụ cột, hoặc liên hệ với Kiến trúc sư Giải pháp AWS hoặc Đại diện Tài khoản của bạn để được hỗ trợ triển khai các lens này trong tổ chức của bạn.\n"},{"uri":"https://vdhxi.github.io/vi/3-blogstranslated/3.6-blog6/","title":"Blog 6","tags":[],"description":"","content":"Công bố AWS Well-Architected Generative AI Lens được cập nhật Chúng tôi vui mừng thông báo bản cập nhật cho AWS Well-Architected Generative AI Lens. Bản cập nhật này có một số phần mới của Well-Architected Generative AI Lens, bao gồm các thực tiễn tốt nhất mới, hướng dẫn kịch bản nâng cao và các lời mở đầu được cải thiện về AI có trách nhiệm, kiến trúc dữ liệu và quy trình làm việc agentic.\nAWS Well-Architected Framework cung cấp các thực tiễn kiến trúc tốt nhất để thiết kế và vận hành các workload generative AI trên AWS. Generative AI Lens sử dụng Well-Architected Framework để phác thảo các bước thực hiện đánh giá Well-Architected Framework cho các workload generative AI của bạn.\nGenerative AI Lens cung cấp một cách tiếp cận nhất quán cho khách hàng để đánh giá các kiến trúc sử dụng các mô hình ngôn ngữ lớn (LLM) để đạt được các mục tiêu kinh doanh của họ. Lens này giải quyết các cân nhắc chung liên quan đến lựa chọn mô hình, kỹ thuật prompt, tùy chỉnh mô hình, tích hợp workload và cải tiến liên tục. Loại trừ cụ thể khỏi Generative AI Lens là các thực tiễn tốt nhất liên quan đến đào tạo mô hình và các kỹ thuật tùy chỉnh mô hình nâng cao. Chúng tôi xác định các thực tiễn tốt nhất giúp bạn kiến trúc các ứng dụng và workload dựa trên đám mây của mình theo các nguyên tắc thiết kế AWS Well-Architected được thu thập từ việc hỗ trợ hàng nghìn triển khai của khách hàng.\nGenerative AI Lens tham gia vào bộ sưu tập các Well-Architected lens được xuất bản dưới AWS Well-Architected Lenses. Để biết thêm thông tin về chính lens này, hãy xem bài đăng thông báo ra mắt.\nCó gì thay đổi trong Generative AI Lens được cập nhật? Generative AI Lens được cập nhật kết hợp một số bổ sung mới để khách hàng xem xét. Những bổ sung này giữ cho lens bắt kịp với lĩnh vực generative AI đang phát triển nhanh chóng, giúp khách hàng cập nhật các thực tiễn kiến trúc tốt nhất.\nHướng dẫn Amazon SageMaker HyperPod Lens được cập nhật có hướng dẫn bổ sung cho người dùng Amazon SageMaker HyperPod. SageMaker HyperPod là một dịch vụ lưu trữ và đào tạo mô hình có khả năng phục hồi cao mà bạn có thể sử dụng để điều phối các quy trình làm việc generative AI phức tạp, chạy lâu dài trên đám mây. Các quy trình làm việc này có thể là đào tạo trước mô hình nền tảng hoặc phục vụ suy luận mô hình ở quy mô lớn.\nChúng tôi rất vui mừng được thông báo hướng dẫn bổ sung cho khách hàng sử dụng SageMaker HyperPod trong Generative AI Lens. Hướng dẫn này được tích hợp vào các thực tiễn tốt nhất hiện có, mở rộng hướng dẫn cho các dịch vụ được bao gồm để bao gồm các khả năng của SageMaker. Hướng dẫn này tham gia vào hướng dẫn hiện có về Amazon Bedrock, Amazon Q Business, Amazon Q Developer, và Amazon SageMaker AI.\nLời mở đầu về Responsible AI Lời mở đầu về AI có trách nhiệm được cập nhật hiện bao gồm một cuộc thảo luận chi tiết về tám khía cạnh cốt lõi của AI có trách nhiệm như được mô tả bởi AWS. Khách hàng hiện có thể tìm hiểu thêm về tám khía cạnh của các hệ thống AI được phát triển có trách nhiệm trực tiếp trong lens. Đây là bài đọc bắt buộc đối với khách hàng trong tất cả các giai đoạn của hành trình generative AI của họ.\nLời mở đầu về kiến trúc dữ liệu Lời mở đầu về kiến trúc dữ liệu được cập nhật xem xét các cân nhắc chiến lược liên quan đến kiến trúc dữ liệu hiện đại hỗ trợ các workload generative AI. Phần này cung cấp cho khách hàng cái nhìn về các quyết định và cân nhắc cấp cao cần thiết để kiến trúc một hệ thống dữ liệu phục vụ các workload generative AI.\nLời mở đầu về Agentic AI Mới đối với generative AI lens là lời mở đầu về agentic AI. Các hệ thống agentic, mặc dù về mặt kỹ thuật được phân loại là một tập hợp con của điện toán phân tán, đóng một vai trò quan trọng trong các workload generative AI hiện đại. Lời mở đầu này giới thiệu cho khách hàng một mẫu các mô hình kiến trúc phổ biến trong các hệ thống agentic được hỗ trợ bởi các mô hình nền tảng.\nCác kịch bản Generative AI Lens hiện bao gồm tám kịch bản kiến trúc. Các kịch bản này bao gồm một loạt các ứng dụng kinh doanh được hỗ trợ bởi generative AI phổ biến, bao gồm các trung tâm cuộc gọi tự động, đồng nghiệp ảo cho nhân viên tri thức và các hệ thống dịch vụ generative AI đa thuê bao (multi-tenant). Phần kịch bản cung cấp hướng dẫn cụ thể để áp dụng các công nghệ generative AI cho các vấn đề kinh doanh phổ biến. Hình ảnh sau đây là một ví dụ về một trong những kịch bản mới hiện được bao gồm trong Generative AI Lens.\nAi nên sử dụng Generative AI Lens? Generative AI Lens hữu ích cho nhiều vai trò. Các nhà lãnh đạo doanh nghiệp có thể sử dụng lens này để có được sự đánh giá rộng hơn về việc triển khai end-to-end và lợi ích của generative AI. Các nhà khoa học dữ liệu và kỹ sư có thể đọc lens này để hiểu cách sử dụng, bảo mật và thu được thông tin chi tiết từ dữ liệu của họ ở quy mô lớn. Các nhà lãnh đạo rủi ro và tuân thủ có thể hiểu cách generative AI được triển khai có trách nhiệm bằng cách cung cấp sự tuân thủ các yêu cầu quy định và quản trị.\nCác bước tiếp theo Well-Architected Generative AI Lens được cập nhật hiện đã có sẵn. Sử dụng lens như một khuôn khổ để xác minh rằng các workload generative AI của bạn được kiến trúc với sự xuất sắc trong vận hành, bảo mật, độ tin cậy, hiệu quả hiệu năng, tối ưu hóa chi phí và tính bền vững trong tâm trí.\nNếu bạn cần hỗ trợ về việc triển khai hoặc đánh giá các workload generative AI của mình, vui lòng liên hệ với Kiến trúc sư Giải pháp AWS hoặc Đại diện Tài khoản của bạn.\nĐặc biệt cảm ơn tất cả mọi người trong các cộng đồng Kiến trúc Giải pháp AWS, Dịch vụ Chuyên nghiệp AWS và Machine Learning đã đóng góp cho Generative AI Lens được cập nhật. Những đóng góp này bao gồm các quan điểm, chuyên môn, nền tảng và kinh nghiệm đa dạng trong việc phát triển AWS Well-Architected Generative AI Lens mới.\nĐể đọc thêm, hãy tham khảo AWS Well-Architected Framework và các sách trắng về trụ cột, hoặc sử dụng AWS Well-Architected Machine Learning Lens và lens tùy chỉnh của nó có thể truy cập từ AWS Well-Architected Tool.\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.5-deploy/5.5.1-setup-ec2/","title":"Cài đặt môi trường EC2 instance","tags":[],"description":"","content":"Cài đặt môi trường cho máy chủ EC2 Trong phần này, chúng ta sẽ thực hiện gán IAM Role cho EC2 và cài đặt các phần mềm cần thiết như Java và MariaDB để chuẩn bị cho việc triển khai ứng dụng.\n1. Gán IAM role cho EC2 Để EC2 instance có quyền truy cập vào các dịch vụ AWS khác (ví dụ: Session Manager để kết nối mà không cần mở port SSH, hoặc truy cập S3, RDS), chúng ta cần gán IAM Role phù hợp.\nTruy cập vào EC2 Dashboard, chọn Instance mà bạn vừa khởi tạo. Chọn Actions -\u0026gt; Security -\u0026gt; Modify IAM role. Chọn IAM Role đã tạo ở các bước trước (ví dụ: EC2RoleForSSM) và nhấn Update IAM role. 2. Cài đặt môi trường Kết nối vào EC2 Instance (sử dụng Session Manager hoặc SSH). Sau đó thực hiện lần lượt các bước sau:\n2.1. Cập nhật hệ thống Chạy lệnh sau để cập nhật các gói phần mềm mới nhất:\nsudo dnf update -y 2.2. Cài đặt Java Ứng dụng của chúng ta chạy trên nền tảng Java, do đó cần cài đặt Java Development Kit (JDK). Ở đây chúng ta sử dụng Amazon Corretto 21 (phiên bản headless phù hợp hơn cho giao diện dòng lệnh không cần đồ hoạ).\nsudo dnf install java-21-amazon-corretto-headless -y Kiểm tra phiên bản Java sau khi cài đặt:\njava -version 2.3. Cài đặt MariaDB Client và Khởi tạo Database Cài đặt MariaDB client để có thể kết nối và thao tác với RDS.\nsudo dnf install mariadb105 -y Kết nối đến RDS database instance mà bạn đã tạo. Thay thế \u0026lt;rds-endpoint\u0026gt;, \u0026lt;username\u0026gt; bằng thông tin thực tế của bạn:\nmysql -h \u0026lt;rds-endpoint\u0026gt; -u \u0026lt;username\u0026gt; -p Sau khi nhập mật khẩu thành công, thực hiện tạo database cho ứng dụng:\nCREATE DATABASE tickets; SHOW DATABASES; 2.4. Cài đặt service để khởi chạy ứng dụng Java Springboot tự động Chạy lệnh sau để tạo file service\nsudo nano /etc/systemd/system/\u0026lt;service-name\u0026gt;.service Nhập nội dung file service, cấu hình biến môi trường cho ứng dụng\nDùng tổ hợp phím Ctrl + O, Enter và Ctrl + X để lưu lại và thoát\nDùng các lệnh sau để áp dụng những thay đổi\nsudo systemctl daemon-reload sudo systemctl restart \u0026lt;service-name\u0026gt; Kiểm tra trạng thái bằng lệnh status Dùng lệnh enable để service có thể tự động chạy cùng lúc mỗi khi EC2 instance start\nsudo systemctl enable \u0026lt;service-name\u0026gt; Lệnh chỉnh múi giờ để đồng bộ (trong trường hợp ứng dụng Java cần có múi giờ phù hợp với giờ Việt Nam)\nsudo timedatectl set-timezone Asia/Ho_Chi_Minh Kiểm tra kết quả bằng lệnh\ndate "},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.4-distribution/5.4.1-ssl-certificate/","title":"Certificate Manager","tags":[],"description":"","content":"AWS Certificate Manager (ACM) Để sử dụng HTTPS, chúng ta cần chứng chỉ SSL.\nCác bước thực hiện Truy cập ACM Console.\nChọn Request a certificate.\nChọn Request a public certificate. Nhập Domain name (ví dụ *.example.com). Chọn DNS validation.\nNhấn Request.\nSau khi request, nhấn vào ID của chứng chỉ, chọn Create records in Route 53 để xác thực tự động. Đợi trạng thái chuyên sang Issued.\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.1-preparation/","title":"Chuẩn bị","tags":[],"description":"","content":"Chuẩn bị môi trường Trước khi đi vào cài đặt các dịch vụ chính, chúng ta cần chuẩn bị lớp mạng (Networking) và quyền truy cập (IAM) cho các tài nguyên.\nNội dung VPC: Tạo Virtual Private Cloud để cô lập mạng cho hệ thống. IAM: Tạo các Role cần thiết cho EC2 truy cập S3, Rekognition, Textract. "},{"uri":"https://vdhxi.github.io/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #1” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"},{"uri":"https://vdhxi.github.io/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #3” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.5-deploy/5.5.2-gitlab/","title":"GitLab CI","tags":[],"description":"","content":"Cấu hình GitLab CI Các bước thực hiện 1. Chuẩn bị biến môi trường (Variables) Vào Settings -\u0026gt; CI/CD -\u0026gt; Variables trên GitLab Repository. Thêm các biến cần thiết:\nEC2_IP SSH_PRIVATE_KEY 2. File cấu hình .gitlab-ci.yml Tạo file .gitlab-ci.yml tại thư mục gốc của dự án. Quy trình gồm:\nBuild: Build file JAR (Spring Boot) hoặc Docker Image. Deploy: Copy file lên EC2 và restart service. Ví dụ pipeline thành công: "},{"uri":"https://vdhxi.github.io/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Thực hành sử dụng các dịch vụ của AWS\nTuần 3: Thiết kế database web đấu giá, lựa chọn các dịch vụ của AWS\nTuần 4: Xây dựng backend web đấu giá, các tính năng đăng kí, đăng nhập, bảo mật, khôi phục tài khoản\nTuần 5: Xây dựng backend web đấu giá, các tính năng quản lí danh mục hệ thống.\nTuần 6: Xây dựng backend web đấu giá, tính năng đấu giá.\nTuần 7: Xây dựng hệ thống web đấu giá, tính năng quản lí ví giao dịch.\nTuần 8: Xây dựng hệ thống web đấu giá, tính năng giao hàng.\nTuần 9: Hoàn thiện backend cho web đấu giá, xây dựng giao diện dự án\nTuần 10: Hoàn thiện giao diện trang chủ, người dùng cho web đấu giá.\nTuần 11: Hoàn thiện giao diện admin, staff cho web đấu giá.\nTuần 12: Hoàn thiện dự án, deploy lên môi trường cloud, testing.\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.1-preparation/5.1.1-vpc/","title":"Tạo VPC","tags":[],"description":"","content":"Khởi tạo Virtual Private Cloud (VPC) Hệ thống sẽ chạy bên trong một mạng riêng ảo (VPC) để đảm bảo bảo mật và cô lập tài nguyên. Chúng ta sẽ tạo VPC với các Public Subnet (cho Load Balancer) và Private Subnet (cho EC2, RDS).\nCác bước thực hiện Truy cập vào AWS Console và tìm kiếm dịch vụ VPC. Chọn Create VPC. Chọn cấu hình VPC and more để tạo nhanh VPC cùng các subnet và Route Table. Điền các thông tin: Name tag: Auction-VPC IPv4 CIDR block: 10.0.0.0/16 Number of Availability Zones (AZs): 2 (để đảm bảo tính sẵn sàng cao) Number of public subnets: 2 Number of private subnets: 2 NAT gateways: None (hoặc 1 per AZ nếu cần EC2 trong private subnet truy cập internet để tải package, nhưng để tiết kiệm chi phí trong bài lab này có thể chọn None hoặc 1). Nhấn Create VPC. Đợi quá trình khởi tạo hoàn tất. "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 08/09/2025 08/09/2025 3 - Tìm hiểu AWS là gì và các loại dịch vụ mà AWS cung cấp, những điều cần lưu ý khi bắt đầu sử dụng dịch vụ của AWS 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/https://www.youtube.com/@AWSStudyGroup 4 - Tạo AWS Free Tier account - Tìm hiểu cách đăng kí AWS Account, cấu hình bảo mật tài khoản 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/https://www.youtube.com/@AWSStudyGroup 5 - Tìm hiểu về cách quản lí chi phí khi sử dụng các dịch vụ của AWS - Thực hành với AWS Budget 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về các khái niệm Region, Availability Zones - Tìm hiểu kiến thức cơ bản về VPC, Public subnet, Private subnet 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/https://www.youtube.com/@AWSStudyGroup Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database AI Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nTạo được Budget plan, biết cách theo dõi các chi phí cho các dịch vụ sử dụng hàng tháng.\nCó khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\nHiểu được các khái niệm về Region, Availability Zone\nHiểu được các tài nguyên trong VPC public subnet, private subnet giao tiếp với nhau và với môi trường internet bên ngoài\n"},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Hiểu được các kiến thức cần thiết khi hosting website trên môi trường cloud Xây dựng và deploy thành công website trên môi trường cloud Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về máy chủ ảo EC2 - Thực hành tạo máy chủ EC2, cấu hình security group, kết nối đến EC2 bằng mobaXterm- Hosting backend tại máy chủ EC2 15/09/2025 15/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu về AWS S3 - Thực hành tạo S3 bucket, upload, quản lí file - Thực hành hosting web với S3 16/09/2025 16/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu về AWS RDS - Thực hành kết nối EC2 và RDS 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu về Route53, CloudFront, AWS SES - Cấu hình quản lí dns cá nhân thông qua Route53- Cấu hình AWS SES để gửi mail 18/09/2025 18/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành hosting website kết hợp EC2, AWS S3, Route53, CloudFront và RDS- Config security group để có thể truy cập SSH vào máy chủ để quản lí - Config elastic IP cho máy chủ EC2 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Tìm hiểu được kiến thức về các dịch vụ cơ bản khi xây dựng website Ứng dụng được các dịch vụ đã tìm hiểu vào việc hosting website Hiểu cách để deploy một website thành công trên môi trường cloud Cấu hình được security group để truy cập SSH đến website, cấu hình và quản lí máy chủ Cài đặt java cho hosting backend java Cài đặt certbot để đăng kí SSL Cài đặt nginx để chuyển truy cập đến máy chủ từ port 8080 giao thức HTTP sang port 443 giao thức HTTPS "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Tìm hiểu và thực hành về quy trình CI/CD tự động Xây dựng dự án website đấu giá dựa trên các service mà AWS hiện đang cung cấp Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Gitlab CI, cách vận hành của gitlab CI- Thực hành sử dụng Gitlab CI để tự động deploy code khi commit 22/09/2025 22/09/2025 https://docs.gitlab.com/ci/ https://codefresh.io/learn/gitlab-ci/ 3 - Phân tích dự án website đấu giá: - Các use case trong hệ thống - Các đối tượng người dùng của hệ thống - Các service sẽ sử dụng để triển khai các tính năng 23/09/2025 23/09/2025 4 - Tìm hiểu về AWS Rekognition và AWS Textract - Thực hành tích hợp Rekognition và Textract vào ứng dụng Springboot 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ https://github.com/awsdocs/aws-doc-sdk-examples/tree/main/javav2/example_code/rekognition 5 - Thiết kế database cho hệ thống web đấu giá 25/09/2025 26/09/2025 6 - Thiết kế database cho hệ thống web đấu giá (tiếp tục) 26/09/2025 26/09/2025 Kết quả đạt được tuần 3: Áp dụng được quy trình CI/CD trong việc phát triển dự án Nắm được cách tích hợp, sử dụng Rekognition và Textract vào ứng dụng Springboot Phân tích được yêu cầu, các use case, các vai trò của người dùng trong hệ thống Thiết kế được database phù hợp với quy mô của hệ thống "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Xây dựng được các API phục vụ cho việc đăng nhập, đăng kí, khôi phục tài khoản Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về JWT Token - Thiết kế quy trình đăng nhập kết hợp xác thực người dùng thực tế, tránh tạo ra nhiều tài khoản ảo - Xây dựng API xác thực tài khoản dựa trên Spring Security, sử dụng Jwt token 29/09/2025 29/09/2025 https://www.youtube.com/watch?v=1XC5WPQkXek\u0026list=PL2xsxmVse9IaxzE8Mght4CFltGOqcG6FC\u0026index=9 3 - Tìm hiểu về Java Mail Sender - Triển khai tính năng gửi mail bằng Java Mail Sender - Xây dựng được API gửi mail đến địa chỉ cụ thể - Triển khai được tính năng bảo mật email OTP 30/09/2025 30/09/2025 https://mailtrap.io/blog/java-send-email/ 4 - Tìm hiểu về hệ thống xác thực 2 bước TOTP Google Authenticator - Tích hợp tính năng xác thực hai bước TOTP vào hệ thống - Xây dựng được API xác minh OTP 1/10/2025 1/10/2025 https://www.youtube.com/watch?v=2m2yuaomCTc 5 - Thiết kế quy trình khôi phục mật khẩu an toàn, bảo mật - Triển khai code, kết hợp các API khác để triển khai quy trình khôi phục mật khẩu 2/10/2025 2/10/2025 6 - API testing, sửa chữa lỗi trong quá trình triển khai để hoàn thiện tính năng và chuẩn bị cho việc sử dụng vào các quy trình khác yêu cầu tính bảo mật 3/10/2025 3/10/2025 Kết quả đạt được tuần 4: Xây dựng được các API phục vụ cho các quy trình: Đăng kí: kiểm tra được tính trùng lập, đồng thời hạn chế được việc spam tạo ra các tài khoản rác. Đăng nhập: xây dựng được quy trình đăng nhập, xác thực thông tin người dùng dựa trên JWT token. Đồng thời tích hợp TOTP nhằm tăng tính bảo mật. Khôi phục mật khẩu: xây dựng được quy trình khôi phục mật khẩu một cách bảo mật, chỉ có người sở hữu thật mới có thể khôi phục mật khẩu bằng việc xác minh qua email và TOTP. Thiết kế được các bước xác thực thông tin, liên kết với nhau tạo thành một quy trình bảo mật nghiêm ngặt nhằm mục đích bảo mật, chỉ chủ sở hữu mới có thể thực hiện. "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Thiết kế, triển khai được các API để: Thay đổi thông tin bảo mật tài khoản Quản lí (thêm, chỉnh sửa, xoá) danh mục hệ thống Quản lí (chỉnh sửa) thông tin người dùng Xây dựng quy trình xác minh tài khoản bằng Rekognition và Textract Quản lí (thêm, chỉnh sửa, xoá) các phiên đấu giá Hiểu và ứng dụng được Redis trong việc cache query để tăng hiệu năng của hệ thống Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Xây dựng API để thay đổi thông tin đăng nhập, thông tin bảo mật tài khoản 6/10/2025 6/10/2025 3 - Xây dựng API để quản lí danh mục hệ thống, quản lí thông tin người dùng - Xây dựng quy trình xác minh thông tin người dùng dựa bằng Rekognition và Textract 7/10/2025 7/10/2025 4 - Xây dựng API để quản lí các phiên đấu giá 8/10/2025 8/10/2025 5 - Tìm hiểu về Redis - Sử dụng Redis để cache query nhằm tăng hiệu năng, giảm tải cho database 9/10/2025 9/10/2025 https://spring.io/projects/spring-data-redis#learn https://viblo.asia/p/huong-dan-spring-boot-redis-aWj53NPGl6m https://kungfutech.edu.vn/bai-viet/spring-boot/su-dung-redis-trong-spring-boot 6 - API testing, sửa chữa các lỗi phát sinh trong quá trình phát triển 10/10/2025 10/10/2025 Kết quả đạt được tuần 5: Triển khai hoàn tất các API sau: API để người dùng đổi mật khẩu, thay đổi email, xác minh mật khẩu. API quản lí địa chỉ, danh mục sản phẩm: Thêm mới, chỉnh sửa, disable. API để người dùng cập nhật thông tin cá nhân: username, avatar. API để staff có quyền chỉnh sửa thông tin người dùng ở các trường dữ liệu cần truy cập trong các use case đặc biệt: trạng thái xác thực, khoá (mở khoá) đăng nhập, xoá thời gian giới hạn giao dịch. API để xác minh thông tin người dùng dựa vào ảnh selfie và giấy tờ tuỳ thân: sử dụng tính năng Face Compare của Rekognition để so sánh độ khớp khuôn mặt và Analyze Document ID của Textract để trích xuất dữ liệu cần thiết. Cấu hình được Redis để cache kết quả khi thực hiện query database, giảm tải cho hệ thống database khi web đấu giá là một hệ thống yêu cầu cao về mặt hiệu năng. "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Tiếp tục xây dựng backend API cho hệ thống web đấu giá Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Fix lỗi các API web đấu giá 13/10/2025 13/10/2025 3 - Fix lỗi các API web đấu giá 14/10/2025 14/10/2025 4 - API testing, kiểm tra và khắc phục các lỗi còn tồn đọng 15/10/2025 15/10/2025 5 - Xây dựng API đặt giá bid, sử dụng redis lock để khắc phục race condition - Thiết kế lại database, chỉnh sửa lại relationship giữa các entity - Tạo các API cơ bản để quản lí ví của người dùng trong hệ thống 16/10/2025 16/10/2025 https://www.anhdh.net/blog/redis-distributed-locking 6 - Xây dựng tính năng gửi yêu cầu hỗ trợ, xử lí yêu cầu hỗ trợ của người dùng - Xây dựng API để staff có thể dừng các phiên đấu giá không hợp lệ 17/10/2025 17/10/2025 Kết quả đạt được tuần 6: Tiếp tục hoàn thiện được các API cho hệ thống web đấu giá: Xây dựng được API đặt bid áp dụng cơ chế Redis lock distributed Thiết kế lại database để phù hợp với các entity hiện tại của hệ thống Xây dựng được các API phục vụ cho use case của role staff trong hệ thống: Dừng các phiên đấu giá không hợp lệ Xử lí ticket của người dùng "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Triển khai xây dựng ví điện tử tích hợp vào hệ thống đấu giá Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tích hợp VnPay cho chức năng nạp tiền vào hệ thống 20/10/2025 20/10/2025 https://sandbox.vnpayment.vn/apis/docs/thanh-toan-pay/pay.html 3 - Fix lỗi VnPay 21/10/2025 21/10/2025 4 - Xây dựng các API phụ trợ cho những chức năng chính: + Xác nhận mã PIN + Thay đổi mã pin + Thay đổi hạn mức chuyển khoản hàng ngày - Tạo API xem lịch sử giao dịch 22/10/2025 22/10/2025 5 - Kết hợp các API xác minh thông tin bảo mật để triển khai các tính năng: + Chuyển tiền + Rút tiền 23/10/2025 23/10/2025 6 - API testing, kiểm tra và khắc phục các lỗi xuất hiện trong quá trình phát triển 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: Triển khai hoàn tất hệ thống ví điện tử vào hệ thống đấu giá, phục vụ cho nhiều logic khác với các chức năng như: Nạp tiền Chuyển tiền Rút tiền Xem lịch sử giao dịch "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Xây dựng quy trình giao hàng sau khi hoàn tất phiên đấu giá Xây dựng cơ chế ràng buộc, kiểm tra điều kiện để tránh việc người dùng spam tạo phiên đấu giá ảo trong hệ thống Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thêm điều kiện kiểm tra trong cơ chế xác thực dữ liệu để người dùng tạo phiên đấu giá mới Chỉnh sử logic code ở các chức năng có liên quan 27/10/2025 27/10/2025 3 - Tạo các API để cập nhật quy trình giao hàng sau đấu giá: + Người bán tạo đơn hàng + Người dùng xác nhận đơn hàng + Cho phép người bán/mua cập nhật đơn hàng 28/10/2025 28/10/2025 4 - Tạo các API cho phép cập nhật trạng thái đơn hàng: + Hoàn thành + Huỷ đơn hàng bởi người mua/bán + Tạo yêu cầu trả hàng hoàn tiền 29/10/2025 29/10/2025 5 - Triển khai quy trình trả hàng hoàn tiền được xử lí bởi role staff - Cập nhật số dư ví và lịch sử giao dịch của người dùng trong các trường hợp 30/10/2025 30/10/2025 6 - API testing, kiểm tra và khắc phục các lỗi xuất hiện trong quá trình phát triển 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: Xây dựng hoàn tất được quy trình giao hàng sau đấu giá:\nTaọ đơn hàng. Người mua/bán xác nhận, cập nhật thông tin. Triển khai hoàn tất quy trình xác nhận hoàn thành, huỷ bỏ, trả hàng hoàn tiền. Cập nhật điều kiện tạo phiên đấu giá, chỉnh sửa logic code ở những API khác để phù hợp với business rule.\n"},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Cấu hình websocket ở backend để gửi thông báo real time Xây dưng giao diện cho hệ thống web đấu giá Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Triển khai websocket để gửi thông báo khi ở backend có các sự kiện mới 3/11/2025 3/11/2025 https://spring.io/guides/gs/messaging-stomp-websocket 3 - Xây dựng các giao diện chính cho hệ thống web đấu giá: + Trang chủ + Trang đăng nhập + Trang đăng kí + Trang quên mật khẩu + Trang hiển thị danh sách đấu giá + Trang chi tiết đấu giá 4/11/2025 4/11/2025 4 - Xây dựng giao diện user cho hệ thống web đấu giá (1) 5/11/2025 6/11/2025 5 - Xây dựng giao diện user cho hệ thống web đấu giá (2) 6/11/2025 6/11/2025 6 - Liên kết API cho các trang chính 7/11/2025 7/11/2025 Kết quả đạt được tuần 9: Cấu hình được WebSocket ở backend để gửi message realtime cho frontend khi có các sự kiện sau:\nCập nhật phiên đấu giá mới. Cập nhật giá, trạng thái mới cho phiên đấu giá. Thông báo biến động số dư. Thông báo về đơn hàng sau khi đấu giá thành công. Xây dựng được giao diện cho các trang chính, liên kết API thành công cho các use case:\nĐăng kí Đăng nhập Đăng nhập với mã xác thực OTP Khôi phục mật khẩu đăng nhập Xem các phiên đấu giá hiện tại Xem chi tiết một phiên đấu giá Xây dựng được giao diện user gồm các trang:\nQuản lí thông tin: Cập nhật thông tin, xác minh thông tin cá nhân. Quản lí các phiên đấu giá: Tạo mới, cập nhật, huỷ bỏ phiên. Quan lí địa chỉ: Tạo mới, cập nhật, xoá. Quản lí ví: Tạo mới, nạp tiền, chuyển tiền, rút tiền, thay đổi mã pin, thay đổi hạn mức, xem lịch sử giao dịch. Quản lí đơn hàng : Xem, chỉnh sửa, xác nhận trạng thái. Quản lí yêu cầu hỗ trợ: Tạo mới, xem. Quản lí thông tin bảo mật: Đổi mật khẩi, email, bật và tắt tính năng xác thực 2 bước. "},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.2-database-storage/5.2.2-elasticache/","title":"Amazon ElastiCache","tags":[],"description":"","content":"Khởi tạo Amazon ElastiCache (Redis) Redis giúp cache các truy vấn thường xuyên và lưu session người dùng.\nCác bước thực hiện 1. Tạo Subnet Group Vào ElastiCache Dashboard -\u0026gt; Subnet groups -\u0026gt; Create subnet group. 2. Tạo Security Group Tạo Security Group cho phép cổng 6379 từ EC2. 3. Tạo Redis Cluster Chọn Redis OSS caches -\u0026gt; Create cache.\nChọn Configure and create a new cluster.\nChọn Cluster mode disabled (để đơn giản và tiết kiệm chi phí). Cấu hình Redis info Cấu hình Node type, ví dụ cache.t3.micro. Chọn Subnet group. Chọn Security Group. Nhấn Create.\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.4-distribution/5.4.2-alb/","title":"Application Load Balancer","tags":[],"description":"","content":"Application Load Balancer (ALB) ALB sẽ phân phối traffic tới các EC2 instance và xử lý SSL termination.\nCác bước thực hiện 1. Tạo Security Group cho ALB Cho phép HTTP (80) và HTTPS (443) từ 0.0.0.0/0. 2. Tạo Target Group Tạo Target Group loại Instances. Protocol HTTP/8080 (Port backend). Register EC2 instances vào Target Group. 3. Tạo Load Balancer Vào Load Balancers -\u0026gt; Create load balancer.\nChọn Application Load Balancer.\nChọn VPC và Public Subnets.\nChọn Security Group vừa tạo.\nCấu hình Listener:\nHTTP:80 -\u0026gt; Redirect to HTTPS (được khuyến nghị). HTTPS:443 -\u0026gt; Forward to Target Group. Tại phần HTTPS listener, chọn ACM Certificate đã tạo. Nhấn Create load balancer.\nSau khi tạo Load Balancer, ta có thể cấu hình lại security group cho EC2 instance chỉ nhận inbound rule từ Load Balancer "},{"uri":"https://vdhxi.github.io/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Auction system build in AWS Cloud infrastructure Hệ thống web đấu giá xây dựng trên nền tảng điện toán đám mây của Amazon Web Service 1. Tóm tắt điều hành Auction system được thiết kế bởi sinh viên FPTU tại TP. Hồ Chí Minh và vận hành trên nền tảng Cloud AWS. Nền tảng tận dụng các dịch vụ AWS để xây dựng một sàn đấu giá trực tuyến với giao diện thân thiện, dễ dàng sử dụng phù hợp với tất cả mọi người\n2. Tuyên bố vấn đề Vấn đề hiện tại\nHiện tại những hệ thống đấu giá vẫn chưa tiếp cận được đến nhiều người bởi vì sự khó tiếp cận. Dự án này ra đời để mang đến một nền tảng đấu giá trực tiếp minh bạch, thân thiện dễ tiếp cận đến mọi người.\nGiải pháp\nNền tảng sử dụng AWS CloudFront và S3 Storage kết hợp ReactJS cung cấp giao diện web , với máy chủ EC2 đảm nhiệm toàn bộ công việc xử lí trên nền tảng Springboot, Amazon S3 để lưu trữ dữ liệu công khai và riêng tư, AWS RDS để lưu trữ cơ sở dữ liệu. Kết hợp cùng Amazon Rekognition và Textract để trích xuất thông tin, xác minh thông tin người dùng để đảm bảo tính công bằng. Với nền tảng này, người dùng có thể đăng ký tài khoản mới, xác thực và tham gia những phiên đấu giá hấp dẫn trên nền tảng.\nLợi ích và hoàn vốn đầu tư (ROI)\nDự án mang đến một nền tảng đấu giá trực tuyến dễ dàng tiếp cận đến mọi người. Chi phí hàng tháng ước tính 59.37 USD (theo AWS Pricing Calculator). Không phát sinh chi phí phát triển thêm.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS để quản lý dữ liệu. Dữ liệu công khai được lưu trữ trong S3 public bucket và hiển thị đến người dùng qua CloudFront và S3 với ReactJS. Mọi thao tác xử lí được thực hiện trên EC2 với nền tảng Springboot. Các thông tin định danh được xử lí bởi Amazon Rekognition và Textract sau đó lưu trữ trong S3 private bucket\nDịch vụ AWS sử dụng\nAWS VPC: Tạo môi trường mạng ảo riêng tư. AWS Route 53: Điều hướng traffic của người dùng. AWS CloudFront: CDN giúp tăng tốc độ tải trang, giảm độ trễ truy cập web. AWS Load Balancing: Nhận request từ internet và điều hướng đến EC2, ổn định ứng dụng. Amazon EC2: Chạy ứng dụng springboot để xử lí backend, giao tiếp với database (RDS), cache query (ElastiCache), gọi các service AI (Rekognition, Textract) và xử lí đấu giá. Amazon S3: Hosting Frontend: Lưu trữ source code của frontend (ReactJS, Tailwind) để CloudFront phân phối. Data storage: 2 bucket (public/private) để lưu trữ ảnh người dùng tải lên phục vụ cho đấu giá và xác minh tài khoản. Amazon ElastiCache: Bộ nhớ đệm, giúp lưu trữ truy vấn giảm tải cho database và tăng tốc độ phản hồi API. Amazon RDS: Lưu trữ dữ liệu chính của hệ thống, được đặt tại private subnet. Amazon Rekognition: Dịch vụ phân tích hình ảnh bằng AI, thực hiện so sánh khuôn mặt (Face Compare) giữa ảnh chụp selfie và ảnh trên giấy tờ tùy thân để xác minh danh tính (eKYC). Amazon Textract: Dịch vụ trích xuất văn bản từ tài liệu. Hệ thống sử dụng Textract để tự động đọc (OCR) và bóc tách thông tin từ ảnh chụp giấy tờ tùy thân để điền tự động cho người dùng. Amazon SES: Backend sử dụng dịch vụ này để gửi email xác thực tài khoản (OTP), thông báo thắng đấu giá hoặc các thông báo hệ thống khác tới người dùng. Amazon CloudWatch: Hệ thống giám sát và quản lý log. Thiết kế thành phần\nTiếp nhận dữ liệu: Dữ liệu từ người dùng. Lưu trữ dữ liệu: Dữ liệu lưu ở 2 S3 bucket (1 cho public và 1 cho private - truy cập qua presigned url) Xử lý dữ liệu: EC2 thực hiện việc xử lí dữ liệu. Giao diện web: Amazon S3 lưu trữ ứng dụng ReactJS. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm các giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu và thiết kế kiến trúc AWS, xác định các dịch vụ sẽ sử dụng, thiết kế database. Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh. Phát triển, kiểm thử, triển khai: Lập trình Springboot và ứng dụng ReactJS, sau đó kiểm thử ở môi trường local. Triển khai trên môi trường Cloud AWS: Thiết lập Gitlab CI, thiết lập môi trường cloud và triển khai. Yêu cầu kỹ thuật\nJava 21 Springboot AWS SDK (S3, Rekognition, Textract, SES) MySQL RDS ReactJS/Vite/TypeScript/Tailwind Gitlab, Gitlab runner CI Postman, CloudWatch 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và thiết kế kiến trúc, thiết kế database, triển khai xây dựng API. Tháng 2: Triển khai xây dựng API, xây dựng giao diện. Tháng 3: Triển khai trên môi trường cloud , kiểm thử, đưa vào sử dụng. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nChi phí hạ tầng\nAmazon Route53: $0.5/tháng (1 hosted zone) S3 Standard: $0.72/tháng (10 GB, 30000 request GET, 1000 request PUT, 5 GB Transfer out) Application Load Balancer: $18.80/tháng (data process 50GB) Amazon EC2 (t3.medium): $16.35/tháng (3yr, no upfront) Amazon ElastiCache (cache.t3.micro): $9.49/tháng (3yr, no upfront) Amazon RDS: $8.38/tháng Rekognition: $0.13/tháng (100 FaceCompare) Textract: $5/tháng (200 Pages document) Tổng: $59.37/tháng.\n7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng lớn, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nChi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nCó backup định kì đề phòng xảy ra sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Giá trị dài hạn: Có thể tái sử dụng cho các dự án khác trong tương lai.\nTham khảo thêm tại Proposal Template\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.2-database-storage/","title":"Database &amp; Storage","tags":[],"description":"","content":"Cài đặt Cơ sở dữ liệu và Lưu trữ Trong phần này, chúng ta sẽ khởi tạo:\nAmazon RDS: Cơ sở dữ liệu quan hệ (MySQL). Amazon ElastiCache: Redis cache. Amazon S3: Lưu trữ object (ảnh, source code). Các dịch vụ này sẽ đóng vai trò backend lưu trữ dữ liệu cho ứng dụng.\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.1-preparation/5.1.2-iam/","title":"Tạo IAM Role","tags":[],"description":"","content":"Tạo IAM Role cho EC2 EC2 cần quyền truy cập vào S3 để lấy code/ảnh, và quyền gọi API của Rekognition và Textract. Thay vì lưu Access Key trong code, ta sẽ dùng IAM Role gán cho EC2.\nCác bước thực hiện Truy cập IAM Dashboard. Chọn Roles -\u0026gt; Create role. Tại bước Trusted entity type, chọn AWS service. Tại Use case, chọn EC2. Nhấn Next. Tại bước Add permissions, tìm và chọn các Policy sau: AmazonS3FullAccess (Hoặc policy giới hạn chỉ bucket của pj). AmazonRekognitionFullAccess. AmazonTextractFullAccess. AmazonSSMManagedInstanceCore (Để remote vào EC2 qua Session Manager nếu cần). Nhấn Next. Đặt tên Role là Auction-EC2-Role. Xem lại và nhấn Create role. "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Hoàn thiện trang user Hoàn thiện trang staff Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Liên kết API cho trang user (1) 10/11/2025 10/11/2025 3 - Liên kết API cho trang user (2) 11/11/2025 11/11/2025 4 - Liên kết API cho trang user (3): - Xây dựng giao diện cho role staff 12/11/2025 12/11/2025 5 - Xây dựng giao diện cho role staff 13/11/2025 13/11/2025 6 - Liên kết API cho trang của role staff 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: Hoàn thiện được trang user với các chức năng được triển khai đầy đủ:\nCập nhật thông tin Xác minh tài khoản Quản lí phiên đấu giá: tạo mới, chỉnh sửa, huỷ bỏ, xem các phiên đang tham gia, theo dõi phiên đấu giá, xem lịch sử Quản lí địa chỉ: tạo mới, cập nhật, xoá Quản lí ví: nạp tiền, chuyển khoản, rút tiền, xem lịch sử giao dịch Quản lí đơn hàng: tạo mới, cập nhật thông tin, cập nhật trạng thái, gửi yêu cầu hoàn tiền Quản lí yêu cầu hỗ trợ: tạo mới, xem lịch sử Quản lí thông tin bảo mật: đổi mật khẩu, email, bật và tắt tính năng xác thực 2 bước Hoàn thiện được trang staff với các chức năng được triển khai đầy đủ:\nQuản lí người dùng: xem thông tin, cập nhật trạng thái xác minh, gỡ bỏ hạn chế tài khoản Quản lí yêu cầu hỗ trợ: xem các yêu cầu hỗ trợ, giám sát đơn hàng, xử lí yêu cầu hoàn tiền "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Tạo được trang admin và hoàn thiện Triển khai được websocket để nhận thông báo message từ backend realtime Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo trang admin - Liên kết được các API 17/11/2025 17/11/2025 3 - Triển khai websocket để nhận thông báo realtime từ backend - Cập nhật lại giao diện ở frontend cho phù hợp với các thông tin cần hiển thị 18/11/2025 18/11/2025 4 - Sửa lỗi websocket khi nhận message từ backend, cập nhật dữ liệu khi nhận message từ backend 19/11/2025 19/11/2025 5 - Sửa lỗi backend khi gửi message đến frontend, cấu hình lại websocket cho phép frontend subscribe websocket 20/11/2025 20/11/2025 6 - Cấu hình, sửa lỗi json với redis ở backend gây lỗi hiển thị ở frontend - Cập nhật lại giao diện trang chi tiết đấu giá ở frontend 21/11/2025 21/11/2025 Kết quả đạt được tuần 11: Hoàn thiện được trang admin để quản lí hệ thống\nQuản lí danh mục: tạo mới, sửa, xoá Quản lí điạ chỉ: tạo mới, sửa, xoá Triển khai được websocket để nhận message realtime từ backend để cập nhật thông tin nhanh chóng:\nCập nhật thông tin khi có đấu giá mới Cập nhật giá và thời gian kết thúc, người thắng khi có bước giá mới được đặt cho 1 phiên đấu giá Cập nhật thông tin số dư ví và lịch sử giao dịch Cập nhật thông báo hệ thống Cấu hình websocket và redis:\nCho phép frontend nhận thông báo riêng tư Sửa lỗi parse Json khi cache data bằng redis "},{"uri":"https://vdhxi.github.io/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Kiểm thử hệ thống web đấu giá, khắc phục các lỗi trong quá trình phát triển Triển khai được hệ thống lên môi trường cloud Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chỉnh sửa lại giao diện, các button, components, font size 24/11/2025 24/11/2025 3 - Sửa các lỗi logic ở backend: + Chỉnh sửa cơ chế đặt cọc số dư khi tạo đấu giá mới + Chỉnh sửa các lỗi logic liên quan đến verify dữ liệu khi đặt đấu giá 25/11/2025 25/11/2025 4 - Triển khai hệ thống lên môi trường cloud AWS, cấu hình biến môi trường 26/11/2025 26/11/2025 https://cloudjourney.awsstudygroup.com/vi/ 5 - Sửa lỗi hệ thống, chỉnh sửa Url mapping khi triển khai trên môi trường cloud AWS - Chỉnh sửa frontend và backend để khắc phục lỗi race condition gây duplicate dữ liệu 27/11/2025 27/11/2025 6 - Tối ưu hoá code backend nhằm tăng hiệu năng, tối ưu query, loại bỏ những service không cần thiết 28/11/2025 28/11/2025 Kết quả đạt được tuần 12: Kiểm thử toàn bộ hệ thống web đấu giá, tiếp tục hoàn thiện những chức năng, giao diện còn lại Triển khai được hệ thống lên môi trường cloud AWS, sử dụng các dịch vụ: AWS EC2 AWS RDS AWS S3 storage AWS Route 53 AWS CloudFront AWS Rekognition AWS Textract Tối ưu hoá hệ thống bằng cách thiết kế lại logic code "},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.4-distribution/5.4.3-cloudfront/","title":"Amazon CloudFront","tags":[],"description":"","content":"Amazon CloudFront CloudFront giúp phân phối nội dung tĩnh từ S3 với độ trễ thấp.\nCác bước thực hiện Truy cập CloudFront Console -\u0026gt; Create distribution.\nTại Origin domain, chọn S3 Bucket Frontend. Tại Origin access, chọn Legacy access identities hoặc OAC (Origin Access Control) để hạn chế người dùng truy cập trực tiếp S3. Chọn Create new OAC.\nViewer protocol policy: Redirect HTTP to HTTPS.\nAllowed HTTP methods: GET, HEAD, OPTIONS.\nWAF: Do not enable (để tiết kiệm). Alternate domain name (CNAME): Điền domain frontend (ví dụ www.example.com).\nCustom SSL certificate: Chọn chứng chỉ ACM. Default root object: index.html. Nhấn Create distribution.\nSau khi tạo, nhớ update Bucket Policy của S3 để cho phép OAC truy cập (Console sẽ gợi ý copy policy).\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.2-database-storage/5.2.3-s3/","title":"Amazon S3","tags":[],"description":"","content":"Khởi tạo Amazon S3 Buckets Chúng ta cần 3 bucket cho các mục đích khác nhau.\n1. Frontend Bucket Dùng để hosting static web (ReactJS).\nTạo bucket với tên unique. Bỏ chọn Block all public access (vì cần public web). Bật Static website hosting. 2. Public Storage Bucket Lưu ảnh sản phẩm đấu giá (public read).\nTạo bucket. Bỏ chọn Block all public access. Cấu hình Bucket Policy cho phép s3:GetObject. 3. Private Storage Bucket Lưu ảnh giấy tờ tùy thân cho việc xác minh tài khoản (private).\nTạo bucket. Giữ nguyên Block all public access. (Tùy chọn) Cấu hình Server-side encryption. "},{"uri":"https://vdhxi.github.io/vi/3-blogstranslated/","title":"Các bài Blog đã dịch","tags":[],"description":"","content":"Phần này sẽ liệt kê và giới thiệu các blog mà bạn đã dịch. Ví dụ:\nBlog 1 - Lợi ích về hiệu năng của các phiên bản tối ưu hóa bộ nhớ Amazon EC2 R8a mới Các phiên bản Amazon EC2 R8a, được hỗ trợ bởi bộ xử lý AMD EPYC thế hệ thứ 5 và băng thông bộ nhớ cao hơn, mang lại những cải tiến hiệu suất đáng kể cho các khối lượng công việc tối ưu hóa bộ nhớ, đặc biệt là cơ sở dữ liệu MySQL. Dựa trên đánh giá HammerDB, R8a cho thấy những mức tăng đáng kể về điểm tổng thể (cao hơn 55% so với R7a và cao hơn 74% so với R6a), số giao dịch mỗi phút (cao hơn 32% so với R7a và cao hơn 63% so với R6a), và giảm độ trễ P99 (thấp hơn 14% so với R7a và thấp hơn 25% so với R6a). Với hiệu suất nhất quán được kích hoạt bởi kiến trúc 1 vCPU = 1 lõi vật lý và khả năng mở rộng mạnh mẽ, R8a trở thành lựa chọn tối ưu cho hệ thống cơ sở dữ liệu và khối lượng công việc thâm dụng bộ nhớ.\nBlog 2 - Tối ưu hóa khối lượng công việc nhạy cảm với độ trễ bằng số liệu thống kê NVMe chi tiết của Amazon EC2 Bài viết này giải thích cách sử dụng số liệu thống kê hiệu suất chi tiết của Amazon EC2 cho các ổ đĩa NVMe instance store để giám sát khối lượng công việc nhạy cảm với độ trễ. Các số liệu mới này cung cấp độ chi tiết theo từng giây cho độ dài hàng đợi, IOPS, thông lượng và biểu đồ độ trễ (bao gồm theo kích thước I/O), giúp xác định các tắc nghẽn hiệu suất và tinh chỉnh ứng dụng. Bài viết bao gồm cách truy cập các số liệu này thông qua nvme-cli hoặc CloudWatch và cung cấp các kịch bản để khắc phục sự cố như vượt quá giới hạn lưu trữ.\nBlog 3 - Cách xuất dữ liệu sang Amazon S3 Tables bằng cách sử dụng AWS Step Functions Distributed Map Bài viết này trình bày một giải pháp không máy chủ để tự động hóa xử lý tài liệu và xuất dữ liệu có cấu trúc sang Amazon S3 Tables bằng cách sử dụng AWS Step Functions Distributed Map. Nó chi tiết hóa một quy trình làm việc có thể mở rộng, kích hoạt khi tải lên S3, sử dụng Distributed Map để xử lý song song các tệp (ví dụ: PDF), trích xuất dữ liệu bằng Amazon Textract và truyền phát nó qua Amazon Data Firehose đến S3 Tables để phân tích sau này với Amazon Athena.\nBlog 4 - DISA STIG cho Amazon Linux 2023 hiện đã có sẵn AWS công bố sự sẵn có của Hướng dẫn Triển khai Kỹ thuật Bảo mật (STIG) cho Amazon Linux 2023 (AL2023), được phát triển với sự cộng tác của DISA. Hướng dẫn này hỗ trợ DOD và các khách hàng liên bang trong việc đáp ứng các tiêu chuẩn tuân thủ bảo mật nghiêm ngặt (NIST 800-53). Bài đăng cũng thảo luận về cách tự động hóa việc triển khai các cấu hình bảo mật này bằng cách sử dụng AWS Systems Manager và EC2 Image Builder cho cả các đội tàu hiện có và hình ảnh mới.\nBlog 5 - Kiến trúc cho sự xuất sắc của AI: AWS ra mắt ba Well-Architected Lenses tại re:Invent 2025 Tại re:Invent 2025, AWS đã giới thiệu các Well-Architected Lenses mới và cập nhật cho AI: Responsible AI Lens mới, và các bản cập nhật cho Machine Learning (ML) Lens và Generative AI Lens. Các lens này cung cấp các phương pháp hay nhất toàn diện để đảm bảo khối lượng công việc AI an toàn, tin cậy, hiệu quả và có trách nhiệm, bao gồm toàn bộ vòng đời từ thử nghiệm đến sản xuất.\nBlog 6 - Công bố AWS Well-Architected Generative AI Lens đã được cập nhật Bài đăng này chi tiết hóa các bản cập nhật cho AWS Well-Architected Generative AI Lens. Các bổ sung chính bao gồm hướng dẫn cho Amazon SageMaker HyperPod, một lời mở đầu Responsible AI mới bao gồm tám khía cạnh cốt lõi, một lời mở đầu Kiến trúc Dữ liệu và một lời mở đầu Agentic AI. Nó cũng bao gồm tám kịch bản kiến trúc mới để giúp khách hàng áp dụng AI tạo sinh vào các vấn đề kinh doanh thông thường một cách hiệu quả.\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.3-compute/","title":"Compute","tags":[],"description":"","content":"Khởi tạo Amazon EC2 Amazon EC2 (Elastic Compute Cloud) sẽ là nơi chạy ứng dụng backend (Spring Boot).\nNội dung EC2 Instance: Máy chủ ảo chạy ứng dụng. Security Group: Tường lửa kiểm soát truy cập. Elastic IP: Địa chỉ IP tĩnh (tùy chọn, cần thiết nếu không dùng Load Balancer hoặc cần IP cố định cho outbound). "},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.4-distribution/5.4.4-route53/","title":"Amazon Route 53","tags":[],"description":"","content":"Amazon Route 53 Cấu hình DNS để trỏ domain về CloudFront (Frontend) và ALB (Backend).\nCác bước thực hiện Truy cập Route 53 -\u0026gt; Hosted zones. Chọn domain của bạn. Route53 sẽ cấp 4 bản ghi NS, hãy cấu hình nó tại nơi đăng kí domain của bạn để có thể quản lí domain tại Route53. Quá trình này mất khoảng vài phút 1. Trỏ về Backend (ALB) Create record. Record name: api (ví dụ api.example.com). Record type: A. Bật Alias. Route traffic to: Alias to Application and Classic Load Balancer. Chọn Region và ALB của bạn. 2. Trỏ về Frontend (CloudFront) Create record. Record name: www hoặc để trống (root domain). Record type: A. Bật Alias. Route traffic to: Alias to CloudFront distribution. Chọn CloudFront distribution. "},{"uri":"https://vdhxi.github.io/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.4-distribution/","title":"Distribution","tags":[],"description":"","content":"Phân phối nội dung Phần này giúp đưa ứng dụng đến người dùng cuối một cách bảo mật và hiệu năng cao.\nNội dung Certificate (ACM): Cấp phát chứng chỉ SSL/TLS miễn phí. Application Load Balancer (ALB): Cân bằng tải cho Backend (Spring Boot). CloudFront: CDN phân phối Frontend (ReactJS) và Static files (S3). Route 53: Quản lý DNS domain. "},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.5-deploy/","title":"CI/CD","tags":[],"description":"","content":"Tích hợp và Triển khai liên tục (CI/CD) Sử dụng GitLab CI để tự động hóa quy trình build và deploy ứng dụng lên AWS.\nNội dung SSH vào EC2 instance để cài đặt những ứng dụng cần thiết GitLab Runner: Cấu hình runner trên EC2 (hoặc dùng Shared Runner). Pipeline: Định nghĩa file .gitlab-ci.yml. "},{"uri":"https://vdhxi.github.io/vi/5-workshop/","title":"Triển khai hệ thống","tags":[],"description":"","content":"Triển khai hệ thống Auction trên AWS Chào mừng bạn đến với workshop triển khai hệ thống đấu giá trực tuyến trên nền tảng AWS. Trong workshop này, chúng ta sẽ cùng nhau xây dựng từng thành phần của hệ thống dựa trên kiến trúc đã đề xuất.\nMục tiêu Hoàn thành việc cài đặt và cấu hình các dịch vụ AWS cần thiết để vận hành hệ thống Auction System.\nKiến trúc Chúng ta sẽ bám sát kiến trúc sau:\nCác bước thực hiện Chuẩn bị (Preparation): Thiết lập VPC, IAM Role. Cơ sở dữ liệu \u0026amp; Lưu trữ (Database \u0026amp; Storage): Cấu hình RDS, ElastiCache, S3. Tính toán (Compute): Cài đặt và cấu hình EC2. Phân phối (Distribution): Cấu hình Load Balancer, CloudFront, Route 53. CI/CD: Thiết lập quy trình triển khai tự động với GitLab CI. Dọn dẹp (Clean up): Xóa tài nguyên sau khi hoàn thành. "},{"uri":"https://vdhxi.github.io/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên (Clean Up) Để tránh phát sinh chi phí không mong muốn sau khi hoàn thành workshop, hãy xóa các tài nguyên theo thứ tự sau:\nThứ tự xóa EC2: Terminate các instance. RDS \u0026amp; ElastiCache: Delete database và cache cluster. Xóa cả Subnet Group và Snapshots. Load Balancer \u0026amp; Target Group: Delete ALB sau đó đến Target Group. CloudFront: Disable distribution, đợi deploy xong rồi Delete. S3: Empty bucket (xóa hết object) sau đó Delete bucket. NAT Gateway \u0026amp; Elastic IP: Delete NAT Gateway -\u0026gt; Release Elastic IP. VPC: Delete VPC (sẽ tự động xóa Subnets, Internet Gateway, Route Table, Security Group liên quan). Lưu ý: Kiểm tra kỹ Billing Dashboard vào ngày hôm sau để chắc chắn không còn chi phí phát sinh.\n"},{"uri":"https://vdhxi.github.io/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại AWS First Cloud AI Journey từ 8/9/2025 đến 30/11/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng Lập trình, phân tích, vận hành dự án, giao tiếp.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ ☐ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://vdhxi.github.io/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc năng động, tích cực. Các thành viên luôn sẵn sàng giúp đỡ, chia sẻ kiến thức mới cho nhau để cùng nhau phát triển. Không gian làm việc gọn gàng, thoải mái, bầu không khí rất chuyên nghiệp nhưng cũng rất thoải mái giúp tăng hiệu quả làm việc.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn khá chi tiết, giải thích rõ khi mình chưa hiểu. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm ở mức rất tốt.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Chính nhờ điều này đã giúp mình có thể thực hiện được những dự án đã ấp ủ từ lâu nhưng vẫn đang loay hoay chưa biết nên thực hiện từ đâu. Bên cạnh đó, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như được tiếp cận và sử dụng các công nghệ mới, sử dụng công cụ quản lý dự án, quy trình làm việc một cách chuyên nghiệp hơn, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hoá công ty rất tích cực: mọi người tương tác hỗ trợ lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Tuy nhiên vẫn có một số ít các bạn thái độ không tốt, không có tinh thần chủ động học hỏi kiến thức mới, chưa làm tốt nhiệm vụ được phân công, thái độ không nghiêm túc với dự án được giao. Tinh thần đồng đội rất tệ.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có tổ chức các buổi event, workshop để chia sẻ kinh nghiệm về những kiến thức mới, đây là một điều tuyệt vời.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Văn hoá làm việc chuyên nghiệp, có quy tắc. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Có quy trình báo cáo tiến độ định kì để tránh xảy ra việc chậm trễ trong việc hoàn thành các dự án. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Có. Vì đây là một môi trường với những kiến thức mới đáng để học hỏi Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://vdhxi.github.io/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://vdhxi.github.io/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]